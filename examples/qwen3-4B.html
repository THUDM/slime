
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Qwen3-4B with 8xH100 &#8212; slime</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=ad20845f" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/qwen3-4B';</script>
    <script src="../_static/js/lang-toggle.js?v=8d03b7be"></script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GLM4-9B with 8xH100" href="glm4-9B.html" />
    <link rel="prev" title="FAQ" href="../get_started/qa.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Sep 04, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="slime - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="slime - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/usage.html">Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/qa.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dense</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Qwen3-4B with 8xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm4-9B.html">GLM4-9B with 8xH100</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MoE</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-30B-A3B.html">Qwen3-30B-A3B with 8xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm4.5-355B-A32B.html">GLM-4.5 with 64xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepseek-r1.html">DeepSeek R1 with 128xH100</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Usage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-4b-base-openhermes.html">SFT Qwen3-4B-Base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/search-r1/README.html">Search-R1 lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/fully_async/README.html">Fully Asynchronous Rollout Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/retool/README.html">Retool: from SFT to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/multi_agent/README.html">Multi-Agent RL</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/speculative-decoding.html">Speculative Decoding – Usage Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/debug.html">Debugging</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../platform_support/amd_tutorial.html">AMD</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Blogs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../blogs/introducing_slime.html">slime: An SGLang-Native Post-Training Framework for RL Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blogs/release_v0.1.0.html">v0.1.0: Redefining High-Performance RL Training Frameworks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/THUDM/slime" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/blob/main/examples/qwen3-4B.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/edit/main/examples/qwen3-4B.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/issues/new?title=Issue%20on%20page%20%2Fexamples/qwen3-4B.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/examples/qwen3-4B.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Qwen3-4B with 8xH100</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-training">Run Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-args">MODEL_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ckpt-args">CKPT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rollout-args">ROLLOUT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#eval-args">EVAL_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-sampling">Dynamic Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-rollout">Partial Rollout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bf16-training-with-fp8-inference">BF16 Training with FP8 Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoupled-training-and-inference">Decoupled Training and Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asynchronous-training">Asynchronous Training</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="qwen3-4b-with-8xh100">
<h1>Qwen3-4B with 8xH100<a class="headerlink" href="#qwen3-4b-with-8xh100" title="Link to this heading">#</a></h1>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">#</a></h2>
<p>After pulling the <code class="docutils literal notranslate"><span class="pre">zhuzilin/slime:latest</span></code> image, initialize the image environment as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/root/
git<span class="w"> </span>clone<span class="w"> </span>https://github.com/THUDM/slime.git
<span class="nb">cd</span><span class="w"> </span>slime/
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</pre></div>
</div>
<p>Download the model and data:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># hf checkpoint</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>Qwen/Qwen3-4B<span class="w"> </span>--local-dir<span class="w"> </span>/root/Qwen3-4B

<span class="c1"># train data</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--repo-type<span class="w"> </span>dataset<span class="w"> </span>zhuzilin/dapo-math-17k<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--local-dir<span class="w"> </span>/root/dapo-math-17k

<span class="c1"># eval data</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>--repo-type<span class="w"> </span>dataset<span class="w"> </span>zhuzilin/aime-2024<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--local-dir<span class="w"> </span>/root/aime-2024
</pre></div>
</div>
<p>Convert the Hugging Face checkpoint into a format that Megatron can load:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># mcore checkpoint</span>
<span class="nb">cd</span><span class="w"> </span>/root/slime
<span class="nb">source</span><span class="w"> </span>scripts/models/qwen3-4B.sh
<span class="nv">PYTHONPATH</span><span class="o">=</span>/root/Megatron-LM<span class="w"> </span>python<span class="w"> </span>tools/convert_hf_to_torch_dist.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="si">${</span><span class="nv">MODEL_ARGS</span><span class="p">[@]</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--hf-checkpoint<span class="w"> </span>/root/Qwen3-4B<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save<span class="w"> </span>/root/Qwen3-4B_torch_dist
</pre></div>
</div>
</section>
<section id="run-training">
<h2>Run Training<a class="headerlink" href="#run-training" title="Link to this heading">#</a></h2>
<p>Execute the training script:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/root/slime
bash<span class="w"> </span>scripts/run-qwen3-4B.sh
</pre></div>
</div>
<section id="parameter-introduction">
<h3>Parameter Introduction<a class="headerlink" href="#parameter-introduction" title="Link to this heading">#</a></h3>
<p>Here, we will briefly introduce the various components of the <a class="reference download internal" download="" href="../_downloads/56a3f7d4f95043db3ddd2596129632f7/run-qwen3-4B.sh"><span class="xref download myst">run-qwen3-4B.sh</span></a> script:</p>
<section id="model-args">
<h4>MODEL_ARGS<a class="headerlink" href="#model-args" title="Link to this heading">#</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SCRIPT_DIR</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="si">}</span><span class="s2">&quot;</span><span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="p">&amp;</span>&gt;/dev/null<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">source</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="si">}</span><span class="s2">/models/qwen3-4B.sh&quot;</span>
</pre></div>
</div>
<p>This reads the model’s configuration from <a class="reference download internal" download="" href="../_downloads/c83b8bca1a19634c809ef60e578486b7/qwen3-4B.sh"><span class="xref download myst">scripts/models/qwen3-4B.sh</span></a>. These are all Megatron parameters. When training with Megatron, it cannot read the model config from the checkpoint, so we need to configure it ourselves. We provide some examples in <a class="reference internal" href="#../../../scripts/models/"><span class="xref myst">scripts/models</span></a>.</p>
<p>⚠️  Ensure that settings such as <code class="docutils literal notranslate"><span class="pre">--rotary-base</span></code> in the model configuration file match the settings of the model you are currently training. This is because different models, even with the same architecture, might use different values. If needed, you can override these parameters in your script after loading the model weights. For instance:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="si">}</span><span class="s2">/models/qwen3-4B.sh&quot;</span>

<span class="nv">MODEL_ARGS</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="o">(</span><span class="w"> </span>--rotary-base<span class="w"> </span><span class="m">10000</span><span class="w"> </span><span class="o">)</span>
</pre></div>
</div>
</section>
<section id="ckpt-args">
<h4>CKPT_ARGS<a class="headerlink" href="#ckpt-args" title="Link to this heading">#</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CKPT_ARGS</span><span class="o">=(</span>
<span class="w">   </span><span class="c1"># HF checkpoint required by sglang; we also read the tokenizer from here</span>
<span class="w">   </span>--hf-checkpoint<span class="w"> </span>/root/Qwen3-4B
<span class="w">   </span><span class="c1"># Checkpoint for the reference model</span>
<span class="w">   </span>--ref-load<span class="w"> </span>/root/Qwen3-4B_torch_dist
<span class="w">   </span><span class="c1"># Load directory for the actor; if empty, it will be loaded from `ref_load`</span>
<span class="w">   </span>--load<span class="w"> </span>/root/Qwen3-4B_slime/
<span class="w">   </span>--save<span class="w"> </span>/root/Qwen3-4B_slime/
<span class="w">   </span>--save-interval<span class="w"> </span><span class="m">20</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="rollout-args">
<h4>ROLLOUT_ARGS<a class="headerlink" href="#rollout-args" title="Link to this heading">#</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">ROLLOUT_ARGS</span><span class="o">=(</span>
<span class="w">   </span><span class="c1"># Prompt dataset, each line is a JSON object</span>
<span class="w">   </span>--prompt-data<span class="w"> </span>/root/dapo-math-17k/dapo-math-17k.jsonl
<span class="w">   </span>--input-key<span class="w"> </span>prompt
<span class="w">   </span>--label-key<span class="w"> </span>label
<span class="w">   </span><span class="c1"># If the `input_key` in the prompt contains an OpenAI message,</span>
<span class="w">   </span><span class="c1"># tokenizer.apply_chat_template(...) will be executed</span>
<span class="w">   </span>--apply-chat-template
<span class="w">   </span><span class="c1"># Whether to shuffle the data</span>
<span class="w">   </span>--rollout-shuffle

<span class="w">   </span><span class="c1"># Reward model type.</span>
<span class="w">   </span><span class="c1"># slime provides many types and --custom-rm-path for custom models</span>
<span class="w">   </span>--rm-type<span class="w"> </span>deepscaler

<span class="w">   </span><span class="c1"># Total number of rollouts to train</span>
<span class="w">   </span>--num-rollout<span class="w"> </span><span class="m">3000</span>
<span class="w">   </span><span class="c1"># Number of prompts in one rollout</span>
<span class="w">   </span>--rollout-batch-size<span class="w"> </span><span class="m">32</span>
<span class="w">   </span><span class="c1"># Number of responses to sample per prompt</span>
<span class="w">   </span><span class="c1"># A rollout will have rollout_batch_size * n_samples_per_prompt samples</span>
<span class="w">   </span>--n-samples-per-prompt<span class="w"> </span><span class="m">8</span>
<span class="w">   </span><span class="c1"># Rollout sampling parameters</span>
<span class="w">   </span>--rollout-max-response-len<span class="w"> </span><span class="m">8192</span>
<span class="w">   </span>--rollout-temperature<span class="w"> </span><span class="m">0</span>.8

<span class="w">   </span><span class="c1"># Number of training steps corresponding to one rollout</span>
<span class="w">   </span>--num-steps-per-rollout<span class="w"> </span><span class="m">1</span>
<span class="w">   </span><span class="c1"># Whether to balance data during training, which might improve speed</span>
<span class="w">   </span>--balance-data
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="eval-args">
<h4>EVAL_ARGS<a class="headerlink" href="#eval-args" title="Link to this heading">#</a></h4>
<p>During evaluation, most rollout parameters are inherited, but we provide some parameters that can override the rollout configuration to allow for different sampling strategies for training and evaluation.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">EVAL_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--eval-interval<span class="w"> </span><span class="m">5</span>
<span class="w">   </span>--eval-prompt-data<span class="w"> </span>/root/aime-2024/aime-2024.jsonl
<span class="w">   </span>--n-samples-per-eval-prompt<span class="w"> </span><span class="m">16</span>
<span class="w">   </span>--eval-max-response-len<span class="w"> </span><span class="m">16384</span>
<span class="w">   </span>--eval-top-p<span class="w"> </span><span class="m">0</span>.7
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="perf-args">
<h4>PERF_ARGS<a class="headerlink" href="#perf-args" title="Link to this heading">#</a></h4>
<p>This is a set of Megatron’s parallelism parameters. Only <code class="docutils literal notranslate"><span class="pre">--use-dynamic-batch-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--max-tokens-per-gpu</span></code> are added by slime.</p>
<p><code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code> specifies the maximum number of tokens each GPU can process. When <code class="docutils literal notranslate"><span class="pre">use_dynamic_batch_size</span></code> is enabled, it attempts to pack data of varying lengths within a batch as close to <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code> as possible, thus forming a dynamic micro-batch size. If a single data item exceeds <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code>, it forms its own batch without being truncated. When context parallelism (CP) is enabled, it allows the CP GPUs to share a total of <code class="docutils literal notranslate"><span class="pre">CP</span> <span class="pre">*</span> <span class="pre">max_tokens_per_gpu</span></code> tokens.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dynamic_batch_size</span></code> is enabled, the traditional <code class="docutils literal notranslate"><span class="pre">micro_batch_size</span></code> is ignored.</p>
<p>⚠️ slime always trains the model using data packing and strictly guarantees per-sample or per-token loss. This means enabling dynamic batch size will not affect the loss calculation. It is recommended to enable it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">PERF_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--tensor-model-parallel-size<span class="w"> </span><span class="m">2</span>
<span class="w">   </span>--sequence-parallel
<span class="w">   </span>--pipeline-model-parallel-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--context-parallel-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--expert-model-parallel-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--expert-tensor-parallel-size<span class="w"> </span><span class="m">1</span>

<span class="w">   </span>--recompute-granularity<span class="w"> </span>full
<span class="w">   </span>--recompute-method<span class="w"> </span>uniform
<span class="w">   </span>--recompute-num-layers<span class="w"> </span><span class="m">1</span>

<span class="w">   </span><span class="c1"># --micro-batch-size 1</span>
<span class="w">   </span>--use-dynamic-batch-size
<span class="w">   </span>--max-tokens-per-gpu<span class="w"> </span><span class="m">9216</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="grpo-args">
<h4>GRPO_ARGS<a class="headerlink" href="#grpo-args" title="Link to this heading">#</a></h4>
<p>Here are some GRPO-related parameters:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GRPO_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--advantage-estimator<span class="w"> </span>grpo
<span class="w">   </span>--use-kl-loss
<span class="w">   </span>--kl-loss-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--kl-loss-type<span class="w"> </span>low_var_kl
<span class="w">   </span>--entropy-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--eps-clip<span class="w"> </span><span class="m">0</span>.2
<span class="w">   </span>--eps-clip-high<span class="w"> </span><span class="m">0</span>.28
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="optimizer-args">
<h4>OPTIMIZER_ARGS<a class="headerlink" href="#optimizer-args" title="Link to this heading">#</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">OPTIMIZER_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--optimizer<span class="w"> </span>adam
<span class="w">   </span>--lr<span class="w"> </span>1e-6
<span class="w">   </span>--lr-decay-style<span class="w"> </span>constant
<span class="w">   </span>--weight-decay<span class="w"> </span><span class="m">0</span>.1
<span class="w">   </span>--adam-beta1<span class="w"> </span><span class="m">0</span>.9
<span class="w">   </span>--adam-beta2<span class="w"> </span><span class="m">0</span>.98
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="sglang-args">
<h4>SGLANG_ARGS<a class="headerlink" href="#sglang-args" title="Link to this heading">#</a></h4>
<p>These are the parameters required by sglang. Here, <code class="docutils literal notranslate"><span class="pre">--rollout-num-gpus-per-engine</span></code> basically corresponds to sglang’s <code class="docutils literal notranslate"><span class="pre">tp_size</span></code>. Other sglang parameters are passed to slime by adding the <code class="docutils literal notranslate"><span class="pre">--sglang-</span></code> prefix.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SGLANG_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--rollout-num-gpus-per-engine<span class="w"> </span><span class="m">2</span>
<span class="w">   </span>--sglang-mem-fraction-static<span class="w"> </span><span class="m">0</span>.7
<span class="o">)</span>
</pre></div>
</div>
<p>⚠️ slime uses <code class="docutils literal notranslate"><span class="pre">sgl-router</span></code> to schedule multiple sglang servers. <code class="docutils literal notranslate"><span class="pre">dp_size</span></code> is not supported when DP attention is disabled.</p>
</section>
</section>
<section id="dynamic-sampling">
<h3>Dynamic Sampling<a class="headerlink" href="#dynamic-sampling" title="Link to this heading">#</a></h3>
<p>slime supports more complex sampling schemes, such as the dynamic sampling in <a class="reference external" href="https://dapo-sia.github.io/">DAPO</a>. To enable dynamic sampling, you need to configure:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">   </span>--over-sampling-batch-size<span class="w"> </span><span class="si">${</span><span class="nv">OVER_SAMPLING_BS</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--dynamic-sampling-filter-path<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>slime.rollout.filter_hub.dynamic_sampling_filters.check_reward_nonzero_std<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">over_sampling_batch_size</span></code> needs to be greater than <code class="docutils literal notranslate"><span class="pre">rollout_batch_size</span></code>. For example, you can configure it as:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="w">   </span>--rollout-batch-size<span class="w"> </span><span class="m">32</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--n-samples-per-prompt<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--over-sampling-batch-size<span class="w"> </span><span class="m">64</span><span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>In this case, the sampling process will directly sample 64 prompts, with 8 samples per prompt. Since slime performs asynchronous sampling internally, we will receive the 8 responses for each prompt sequentially. Upon receiving the responses, the function specified by <code class="docutils literal notranslate"><span class="pre">dynamic_sampling_filter_path</span></code> is used for filtering. If the samples pass the filter, these 8 data points are kept; otherwise, they are discarded. The function in the example checks if the rewards for the samples are not all identical (i.e., not all correct or all incorrect):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">check_reward_nonzero_std</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">samples</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="n">Sample</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">rewards</span> <span class="o">=</span> <span class="p">[</span><span class="n">sample</span><span class="o">.</span><span class="n">reward</span> <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">samples</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mf">0.0</span>
</pre></div>
</div>
<p>When we have received 32 * 8 data points, we will immediately stop the current sampling round and will not wait for the remaining data to be sampled. If more than 32 prompts’ worth of data is discarded (leaving fewer than 32 prompts’ worth), we will then sample another 64 prompts.</p>
</section>
<section id="partial-rollout">
<h3>Partial Rollout<a class="headerlink" href="#partial-rollout" title="Link to this heading">#</a></h3>
<p>During the process of dynamic sampling, a large number of requests are aborted prematurely. We can configure the <code class="docutils literal notranslate"><span class="pre">--partial-rollout</span></code> parameter to save these partially generated requests to a data buffer. In the next rollout, these requests can be retrieved to continue data generation, thereby further optimizing performance.</p>
<p>You can customize how data is retrieved from the buffer by configuring the <code class="docutils literal notranslate"><span class="pre">--buffer-filter-path</span></code>. The default function is:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">pop_first</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">rollout_id</span><span class="p">,</span> <span class="n">buffer</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Sample</span><span class="p">]],</span> <span class="n">num_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Sample</span><span class="p">]]:</span>
    <span class="n">num_to_pop</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">buffer</span><span class="p">),</span> <span class="n">num_samples</span><span class="p">)</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">buffer</span><span class="p">[:</span><span class="n">num_to_pop</span><span class="p">]</span>
    <span class="k">del</span> <span class="n">buffer</span><span class="p">[:</span><span class="n">num_to_pop</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">samples</span>
</pre></div>
</div>
<p>This means that each time, the data corresponding to the first <code class="docutils literal notranslate"><span class="pre">num_samples</span></code> prompts is retrieved, totaling <code class="docutils literal notranslate"><span class="pre">num_samples</span> <span class="pre">*</span> <span class="pre">n_samples_per_prompt</span></code> items.</p>
<p>⚠️ The <code class="docutils literal notranslate"><span class="pre">sample.metadata</span></code> of each partial rollout sample stores the rollout ID from its initial generation, which can be used for data filtering.</p>
</section>
<section id="bf16-training-with-fp8-inference">
<h3>BF16 Training with FP8 Inference<a class="headerlink" href="#bf16-training-with-fp8-inference" title="Link to this heading">#</a></h3>
<p>slime also supports BF16 training with FP8 inference. For the Qwen3-4B model, you just need to download the following model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>huggingface-cli<span class="w"> </span>download<span class="w"> </span>Qwen/Qwen3-4B-FP8<span class="w"> </span>--local-dir<span class="w"> </span>/root/Qwen3-4B-FP8
</pre></div>
</div>
<p>And replace <code class="docutils literal notranslate"><span class="pre">--hf-checkpoint</span></code> with:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1">#--hf-checkpoint /root/Qwen3-4B</span>
--hf-checkpoint<span class="w"> </span>/root/Qwen3-4B-FP8
</pre></div>
</div>
<p>This will trigger FP8 inference. Currently, we directly cast the BF16 weights to FP8. In the future, we will gradually add more sophisticated quantization schemes that have less impact on precision.</p>
<p>⚠️ The Megatron checkpoint for training still needs to be the one that was originally converted from the BF16 Hugging Face model.</p>
</section>
<section id="decoupled-training-and-inference">
<h3>Decoupled Training and Inference<a class="headerlink" href="#decoupled-training-and-inference" title="Link to this heading">#</a></h3>
<p>In the original script, the resource configuration is as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ray<span class="w"> </span>job<span class="w"> </span>submit<span class="w"> </span>...<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--<span class="w"> </span>python3<span class="w"> </span>train.py<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--actor-num-nodes<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--actor-num-gpus-per-node<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--colocate<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>...
</pre></div>
</div>
<p>This enables co-located training and inference, where the training part uses 1 machine with 8 GPUs, and inference shares these 8 GPUs with training.</p>
<p>If you want to use the decoupled training and inference feature, you need to remove <code class="docutils literal notranslate"><span class="pre">--colocate</span></code> and configure <code class="docutils literal notranslate"><span class="pre">--rollout-num-gpus</span></code>. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ray<span class="w"> </span>job<span class="w"> </span>submit<span class="w"> </span>...<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--<span class="w"> </span>python3<span class="w"> </span>train.py<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--actor-num-nodes<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--actor-num-gpus-per-node<span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--rollout-num-gpus<span class="w"> </span><span class="m">6</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>...
</pre></div>
</div>
<p>In this case, 2 GPUs will be allocated for training, and 6 GPUs will be allocated for inference.</p>
<p>⚠️  If the concurrency on each sglang server is too high, it may exceed sglang’s default CUDA graph concurrency limit (the default maximum is 160), which will affect inference speed. You can adjust this in the following two ways:</p>
<ol class="arabic">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">--sglang-server-concurrency</span></code> to limit the maximum number of concurrent requests sent to a single sglang server. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--sglang-server-concurrency<span class="w"> </span><span class="m">160</span>
</pre></div>
</div>
</li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">--sglang-cuda-graph-bs</span></code> (which corresponds to sglang’s native <code class="docutils literal notranslate"><span class="pre">--cuda-graph-bs</span></code> argument) to increase the number of CUDA graphs initialized by sglang. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>--sglang-cuda-graph-bs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="k">$(</span>seq<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">256</span><span class="k">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="asynchronous-training">
<h3>Asynchronous Training<a class="headerlink" href="#asynchronous-training" title="Link to this heading">#</a></h3>
<p>When you separate training and inference, you may notice that the training and inference GPUs are always waiting for each other. To prevent these resources from being idle, we can enable asynchronous training. This can be done by changing <code class="docutils literal notranslate"><span class="pre">train.py</span></code> to <code class="docutils literal notranslate"><span class="pre">train_async.py</span></code> in the startup script. By doing this, slime will generate data for the next rollout while training on the current one.</p>
<p>The only difference between <code class="docutils literal notranslate"><span class="pre">train.py</span></code> and <code class="docutils literal notranslate"><span class="pre">train_async.py</span></code> lies in the synchronization logic of the training loop. We achieve this by using Ray’s asynchronous features (<code class="docutils literal notranslate"><span class="pre">.remote</span></code>, <code class="docutils literal notranslate"><span class="pre">ray.get</span></code>).</p>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../get_started/qa.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">FAQ</p>
      </div>
    </a>
    <a class="right-next"
       href="glm4-9B.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">GLM4-9B with 8xH100</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#run-training">Run Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#model-args">MODEL_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ckpt-args">CKPT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#rollout-args">ROLLOUT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#eval-args">EVAL_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamic-sampling">Dynamic Sampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#partial-rollout">Partial Rollout</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bf16-training-with-fp8-inference">BF16 Training with FP8 Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decoupled-training-and-inference">Decoupled Training and Inference</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asynchronous-training">Asynchronous Training</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By slime Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-2025, slime.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Sep 04, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>