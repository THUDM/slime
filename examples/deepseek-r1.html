
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>DeepSeek R1 with 128xH100 &#8212; slime</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=ad20845f" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/deepseek-r1';</script>
    <script src="../_static/js/lang-toggle.js?v=8d03b7be"></script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Reproducibility" href="../_examples_synced/reproducibility/README.html" />
    <link rel="prev" title="GLM-4.5 with 64xH100" href="glm4.5-355B-A32B.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Oct 25, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="slime - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="slime - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/usage.html">Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/qa.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Dense</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-4B.html">Qwen3-4B with 8xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm4-9B.html">GLM4-9B with 8xH100</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">MoE</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-30B-A3B.html">Qwen3-30B-A3B with 8xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm4.5-355B-A32B.html">GLM-4.5 with 64xH100</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">DeepSeek R1 with 128xH100</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/reproducibility/README.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/speculative-decoding.html">Speculative Decoding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/fault-tolerance.html">Fault Tolerance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/arch-support-beyond-megatron.html">Supporting Model Architectures Beyond Megatron-LM</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Other Usage</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-4b-base-openhermes.html">SFT Qwen3-4B-Base</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/search-r1/README.html">Search-R1 lite</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/fully_async/README.html">Fully Asynchronous Rollout Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/retool/README.html">Retool: from SFT to RL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../_examples_synced/multi_agent/README.html">Multi-Agent RL</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/debug.html">Debugging</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../platform_support/amd_tutorial.html">AMD</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Blogs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../blogs/release_v0.1.0.html">v0.1.0: Redefining High-Performance RL Training Frameworks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../blogs/introducing_slime.html">slime: An SGLang-Native Post-Training Framework for RL Scaling</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/THUDM/slime" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/blob/main/examples/deepseek-r1.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/edit/main/examples/deepseek-r1.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/THUDM/slime/issues/new?title=Issue%20on%20page%20%2Fexamples/deepseek-r1.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/examples/deepseek-r1.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>DeepSeek R1 with 128xH100</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#executing-the-training">Executing the Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ckpt-args">CKPT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-args">MISC_ARGS</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="deepseek-r1-with-128xh100">
<h1>DeepSeek R1 with 128xH100<a class="headerlink" href="#deepseek-r1-with-128xh100" title="Link to this heading">#</a></h1>
<p>This is an example of doing DeepSeek R1 RL training using 128xH100 GPUs.</p>
<p>We will use bf16 for training, and an fp8 format with 128x128 blockwise quantization for inference. The maximum response length is 32k, and dynamic sampling will be used to filter data during training.</p>
<p>Regarding parallelism, for sglang we will enable EP64, activate dp attention, and deepep. For the Megatron part, we will use TP8, PP4, EP32, and CP4.</p>
<p>⚠️ To save GPU memory, we will use CPU Adam. Each node (8xH100) will occupy 1.4~1.5TB of host memory. If a single machine’s host memory is insufficient, this can be resolved by adding more GPUs to expand the parallelism.</p>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">#</a></h2>
<p>For instructions on setting up the environment and downloading data, please refer to <a class="reference internal" href="qwen3-4B.html"><span class="std std-doc">Example: Qwen3-4B</span></a>.</p>
<p>To prepare the DeepSeek R1 checkpoint, first you will need to download DeepSeek-R1 to a directory accessible by all machines (hereinafter referred to as <code class="docutils literal notranslate"><span class="pre">$BASE_DIR</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>huggingface-cli<span class="w"> </span>download<span class="w"> </span>deepseek-ai/DeepSeek-R1<span class="w"> </span>--local-dir<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1
</pre></div>
</div>
<p>The Hugging Face checkpoint for DeepSeek-R1 is in a block-quantized fp8 format. To convert it into a torch_dist format that Megatron can load, you first need to convert it to a bf16 Hugging Face checkpoint:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>slime/
python<span class="w"> </span>tools/fp8_cast_bf16.py<span class="w"> </span>--input-fp8-hf-path<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1<span class="w"> </span>--output-bf16-hf-path<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1-bf16/
</pre></div>
</div>
<p>Next, we need to convert the bf16 version of DeepSeek-R1 into the torch_dist format. Specifically, execute the following on 4 separate nodes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>slime/
<span class="nb">source</span><span class="w"> </span>scripts/models/deepseek-v3.sh
<span class="nv">PYTHONPATH</span><span class="o">=</span>/root/Megatron-LM/<span class="w"> </span>torchrun<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--nproc-per-node<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--master-addr<span class="w"> </span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span><span class="w"> </span>--master-port<span class="w"> </span><span class="m">12345</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--nnodes<span class="o">=</span><span class="m">4</span><span class="w"> </span>--node-rank<span class="w"> </span><span class="si">${</span><span class="nv">NODE_RANK</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>tools/convert_hf_to_torch_dist.py<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="si">${</span><span class="nv">MODEL_ARGS</span><span class="p">[@]</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--tensor-model-parallel-size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--pipeline-model-parallel-size<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--expert-tensor-parallel-size<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--expert-model-parallel-size<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--decoder-first-pipeline-num-layers<span class="w"> </span><span class="m">7</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--decoder-last-pipeline-num-layers<span class="w"> </span><span class="m">6</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--hf-checkpoint<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1-bf16/<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--save<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1_torch_dist/
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">MASTER_ADDR</span></code> is the IP of node0, and <code class="docutils literal notranslate"><span class="pre">NODE_RANK</span></code> indicates the node’s index, both configured similarly to a multi-node <code class="docutils literal notranslate"><span class="pre">torchrun</span></code> setup.</p>
</section>
<section id="executing-the-training">
<h2>Executing the Training<a class="headerlink" href="#executing-the-training" title="Link to this heading">#</a></h2>
<p>On node0, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>slime/
bash<span class="w"> </span>scripts/run-deepseek-r1.sh
</pre></div>
</div>
<p>On other nodes, you need to join the Ray cluster with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ray<span class="w"> </span>start<span class="w"> </span>--address<span class="o">=</span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span>:6379<span class="w"> </span>--num-gpus<span class="w"> </span><span class="m">8</span><span class="w"> </span>--node-ip-address<span class="w"> </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="w"> </span>--disable-usage-stats<span class="s2">&quot;</span>
</pre></div>
</div>
<p>Alternatively, if you have a list of all node IPs, for example, an MPI hostfile (where each line is <code class="docutils literal notranslate"><span class="pre">ip</span> <span class="pre">slot=8</span></code>), you can add the following commands after the <code class="docutils literal notranslate"><span class="pre">ray</span> <span class="pre">start</span> <span class="pre">--head</span></code> command in <code class="docutils literal notranslate"><span class="pre">scripts/run-deepseek-r1.sh</span></code>. This allows you to execute the training entirely from node0:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span>WORKER_IP<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="nv">$BASE_DIR</span>/mpi_hostfile<span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="o">[[</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$WORKER_IP</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$MASTER_ADDR</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="k">continue</span>
<span class="w">  </span><span class="k">fi</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Starting Ray worker on </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="w">  </span>ssh<span class="w"> </span>root@<span class="s2">&quot;</span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="s2">&quot;pkill -9 sglang ; ray stop --force ; pkill -9 python ; ray start --address=</span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span><span class="s2">:6379 --num-gpus 8 --node-ip-address </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2"> --disable-usage-stats&quot;</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
<span class="nb">wait</span>
</pre></div>
</div>
<section id="parameter-introduction">
<h3>Parameter Introduction<a class="headerlink" href="#parameter-introduction" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SCRIPT_DIR</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="si">}</span><span class="s2">&quot;</span><span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="p">&amp;</span>&gt;/dev/null<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">source</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="si">}</span><span class="s2">/models/deepseek-v3.sh&quot;</span>
</pre></div>
</div>
<p>This reads the model’s config from <a class="reference download internal" download="" href="../_downloads/8cec77fffdc7e04384198c07d89b792c/deepseek-v3.sh"><span class="xref download myst">scripts/models/deepseek-v3.sh</span></a>. These configs are all Megatron parameters. When training with Megatron, it cannot read the model config from the checkpoint, so we need to configure it ourselves. We provide some examples in <a class="reference internal" href="#../../../scripts/models/"><span class="xref myst">scripts/models</span></a>.</p>
<section id="ckpt-args">
<h4>CKPT_ARGS<a class="headerlink" href="#ckpt-args" title="Link to this heading">#</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">CKPT_ARGS</span><span class="o">=(</span>
<span class="w">   </span><span class="c1"># HF ckpt required by sglang, we also read the tokenizer from here</span>
<span class="w">   </span>--hf-checkpoint<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1/
<span class="w">   </span><span class="c1">#--hf-checkpoint $BASE_DIR/DeepSeek-R1-bf16/</span>
<span class="w">   </span>--ref-load<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1_torch_dist/
<span class="w">   </span><span class="c1"># Actor&#39;s load directory, if empty, it will read from `ref_load`</span>
<span class="w">   </span>--load<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1_slime/
<span class="w">   </span>--save<span class="w"> </span><span class="nv">$BASE_DIR</span>/DeepSeek-R1_slime/
<span class="w">   </span>--save-interval<span class="w"> </span><span class="m">20</span>
<span class="o">)</span>
</pre></div>
</div>
<p>slime will perform online quantization during training based on the quantization configuration in <code class="docutils literal notranslate"><span class="pre">hf_checkpoint</span></code>. For instance, in the current example, we are using the fp8 checkpoint of DeepSeek R1. This means that when updating parameters, we will first perform blockwise quantization on the parameters before passing them to sglang.</p>
</section>
<section id="perf-args">
<h4>PERF_ARGS<a class="headerlink" href="#perf-args" title="Link to this heading">#</a></h4>
<p>A set of Megatron parallelism parameters. Only <code class="docutils literal notranslate"><span class="pre">--use-dynamic-batch-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--max-tokens-per-gpu</span></code> are added by slime.</p>
<p>For the Megatron part, we have configured TP8, PP4, CP4, and EP32. Since DeepSeek-R1 has 61 layers, which is not divisible by 4, we have specifically configured the last pipeline stage to have 13 layers.</p>
<p><code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code> refers to the maximum number of tokens each GPU can process. When <code class="docutils literal notranslate"><span class="pre">use_dynamic_batch_size</span></code> is enabled, it will pack data of varying lengths within a batch as close to <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code>. If a single data item exceeds <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code>, it will form its own batch without truncation. When context parallelism (CP) is enabled, it allows CP GPUs to share a total length of <code class="docutils literal notranslate"><span class="pre">CP</span> <span class="pre">*</span> <span class="pre">max_tokens_per_gpu</span></code> tokens.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dynamic_batch_size</span></code> is enabled, the traditional <code class="docutils literal notranslate"><span class="pre">micro_batch_size</span></code> is ignored.</p>
<p>⚠️ slime always trains the model using data packing and strictly guarantees per-sample or per-token loss. This means enabling dynamic batch size will not affect the loss calculation. It is recommended to enable it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">PERF_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--tensor-model-parallel-size<span class="w"> </span><span class="m">8</span>
<span class="w">   </span>--sequence-parallel
<span class="w">   </span>--pipeline-model-parallel-size<span class="w"> </span><span class="m">4</span>
<span class="w">   </span>--context-parallel-size<span class="w"> </span><span class="m">4</span>
<span class="w">   </span>--expert-model-parallel-size<span class="w"> </span><span class="m">32</span>
<span class="w">   </span>--expert-tensor-parallel-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--decoder-last-pipeline-num-layers<span class="w"> </span><span class="m">13</span>

<span class="w">   </span>--recompute-granularity<span class="w"> </span>full
<span class="w">   </span>--recompute-method<span class="w"> </span>uniform
<span class="w">   </span>--recompute-num-layers<span class="w"> </span><span class="m">1</span>

<span class="w">   </span>--use-dynamic-batch-size
<span class="w">   </span>--max-tokens-per-gpu<span class="w"> </span><span class="m">16384</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="grpo-args">
<h4>GRPO_ARGS<a class="headerlink" href="#grpo-args" title="Link to this heading">#</a></h4>
<p>Currently, these are some GRPO-related parameters in slime:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GRPO_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--advantage-estimator<span class="w"> </span>grpo
<span class="w">   </span>--use-kl-loss
<span class="w">   </span>--kl-loss-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--kl-loss-type<span class="w"> </span>low_var_kl
<span class="w">   </span>--entropy-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--eps-clip<span class="w"> </span><span class="m">0</span>.2
<span class="w">   </span>--eps-clip-high<span class="w"> </span><span class="m">0</span>.28
<span class="o">)</span>
</pre></div>
</div>
<p>If you wish to train without loading the reference model, you need to remove <code class="docutils literal notranslate"><span class="pre">--use-kl-loss</span></code> and set <code class="docutils literal notranslate"><span class="pre">--kl-coef</span> <span class="pre">0.00</span></code> (the default value is 0).</p>
</section>
<section id="optimizer-args">
<h4>OPTIMIZER_ARGS<a class="headerlink" href="#optimizer-args" title="Link to this heading">#</a></h4>
<p>We have configured CPU Adam with the following parameters to save GPU memory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">OPTIMIZER_ARGS</span><span class="o">=(</span>
<span class="w">   </span>...

<span class="w">   </span>--optimizer-cpu-offload
<span class="w">   </span>--overlap-cpu-optimizer-d2h-h2d
<span class="w">   </span>--use-precision-aware-optimizer
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="sglang-args">
<h4>SGLANG_ARGS<a class="headerlink" href="#sglang-args" title="Link to this heading">#</a></h4>
<p>These are the parameters required by sglang. Here, <code class="docutils literal notranslate"><span class="pre">--rollout-num-gpus-per-engine</span></code> basically corresponds to sglang’s <code class="docutils literal notranslate"><span class="pre">tp_size</span></code>. Other sglang parameters are passed to slime by adding a <code class="docutils literal notranslate"><span class="pre">--sglang-</span></code> prefix. To fully leverage sglang’s large EP inference capabilities, we have added configurations like ep64, dp_attention dp8, and deepep mode auto.</p>
<p>The final <code class="docutils literal notranslate"><span class="pre">--sglang-server-concurrency</span></code> is a parameter specific to slime. It is used to prevent the sglang server’s concurrent requests from becoming too large and crashing the HTTP server. The default is 512. However, since we now have one server for 8 nodes, we have adjusted it to 1024 to ensure that each dp rank can have a concurrency of 128.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SGLANG_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--rollout-num-gpus-per-engine<span class="w"> </span><span class="m">64</span>
<span class="w">   </span>--sglang-mem-fraction-static<span class="w"> </span><span class="m">0</span>.7
<span class="w">   </span>--sglang-enable-ep-moe

<span class="w">   </span><span class="c1"># dp attention</span>
<span class="w">   </span>--sglang-enable-dp-attention
<span class="w">   </span>--sglang-dp-size<span class="w"> </span><span class="m">8</span>
<span class="w">   </span>--sglang-moe-dense-tp-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--sglang-enable-dp-lm-head
<span class="w">   </span>--sglang-disable-radix-cache

<span class="w">   </span><span class="c1"># enable deepep for sglang</span>
<span class="w">   </span>--sglang-enable-deepep-moe
<span class="w">   </span>--sglang-deepep-mode<span class="w"> </span>auto

<span class="w">   </span><span class="c1"># make every dp rank have 128 concurrency</span>
<span class="w">   </span>--sglang-server-concurrency<span class="w"> </span><span class="m">1024</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="misc-args">
<h4>MISC_ARGS<a class="headerlink" href="#misc-args" title="Link to this heading">#</a></h4>
<p>Some additional Megatron configurations. Note that Megatron’s deepep is configured here.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">MISC_ARGS</span><span class="o">=(</span>
<span class="w">   </span>...

<span class="w">   </span><span class="c1"># use deepep for megatron</span>
<span class="w">   </span>--moe-enable-deepep
<span class="w">   </span>--moe-token-dispatcher-type<span class="w"> </span>flex
<span class="o">)</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="glm4.5-355B-A32B.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">GLM-4.5 with 64xH100</p>
      </div>
    </a>
    <a class="right-next"
       href="../_examples_synced/reproducibility/README.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Reproducibility</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#executing-the-training">Executing the Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#ckpt-args">CKPT_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-args">MISC_ARGS</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By slime Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-2025, slime.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Oct 25, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>