# Speculative decoding ä½¿ç”¨æŒ‡å—

### æ”¯æŒæƒ…å†µ
- âœ… mtp layer ä»…æ¨ç†ï¼Œä¸è®­ç»ƒ
	- âœ… æ‹¥æœ‰åŸç”Ÿ mtp layer çš„æ¨¡å‹
		- âœ… Mimo-7B-RL
		- ğŸ§ª Deepseek-V3/R1
		- ğŸ§ª GLM-4.5
	- ğŸš§ SpecForge è®­ç»ƒçš„å¤–éƒ¨ draft model
		- âœ… [sglang-EAGLE3-LLaMA3.1-Instruct-8B](https://huggingface.co/lmsys/sglang-EAGLE3-LLaMA3.1-Instruct-8B)
		- ğŸš§ [Qwen3-235B-A22B-EAGLE3](https://huggingface.co/lmsys/Qwen3-235B-A22B-EAGLE3)
- â³ mtp layer çš„ RL è®­ç»ƒ
	- ğŸš§ åœ¨Megatron æ”¯æŒ mtp layer çš„ sequence packing
### ä½¿ç”¨æ–¹æ³•
åœ¨ SGLANG_ARGS é‡Œæ·»åŠ å¦‚ä¸‹å‚æ•°
```bash
# for speculative decoding
--sglang-speculative-algorithm EAGLE
--sglang-speculative-num-steps 3
--sglang-speculative-eagle-topk 1
--sglang-speculative-num-draft-tokens 4
```

#### Llama 3.1 8B EAGLE3 é…ç½®ç¤ºä¾‹
å¯¹äºä½¿ç”¨ [sglang-EAGLE3-LLaMA3.1-Instruct-8B](https://huggingface.co/lmsys/sglang-EAGLE3-LLaMA3.1-Instruct-8B) ä½œä¸º draft model çš„é…ç½®ï¼š

```bash
SGLANG_ARGS=(
   --rollout-num-gpus-per-engine 1
   --sglang-mem-fraction-static 0.8

   --sglang-speculative-algorithm EAGLE3
   --sglang-speculative-draft-model-path /root/sglang-EAGLE3-LLaMA3.1-Instruct-8B
   --sglang-speculative-num-steps 5
   --sglang-speculative-eagle-topk 8
   --sglang-speculative-num-draft-tokens 32

   --sglang-max-running-requests 48
   --sglang-dtype float16
   --sglang-context-length 2048  # å— draft model é™åˆ¶
   --sglang-attention-backend fa3
)
```

**é‡è¦é…ç½®è¯´æ˜ï¼š**
- `--sglang-dtype float16`ï¼šè¿™é‡Œå¿…é¡»è¦é…ï¼ˆå•èµ· sglang ä¹Ÿéœ€è¦ï¼‰ã€‚å› ä¸º `sglang-EAGLE3-LLaMA3.1-Instruct-8B` æ˜¯ `float16`,`Llama-3.1-8B-Instruct` æ˜¯ `bfloat16`ï¼ŒäºŒè€…ä¸ä¸€è‡´ï¼Œå¦‚æœä¸æ‰‹åŠ¨æŒ‡å®šè€Œæ˜¯ä»å„è‡ªçš„ config.json é‡Œè¯»å–ä¼šæŠ¥ `Capture cuda graph failed`
- `--sglang-context-length 2048`ï¼š`sglang-EAGLE3-LLaMA3.1-Instruct-8B` çš„`max_position_embeddings=2048`ï¼Œç›®å‰ sglang çš„å®ç°å¼ºåˆ¶è¦æ±‚ target model å’Œ draft model çš„content length ä¸€è‡´ 
- `--sglang-attention-backend fa3`ï¼šé¿å… flashInfer çš„é—®é¢˜ï¼ˆhttps://github.com/sgl-project/sglang/issues/9888ï¼‰
- å®Œæ•´é…ç½®ç¤ºä¾‹å¯å‚è€ƒ `scripts/run-eagle3-llama3.1-8B.sh`

è¯¦ç»†å‚æ•°å«ä¹‰åŠé…ç½®æ–¹æ³•ï¼Œè¯·å‚è€ƒ SGLang çš„ speculative decoding [æ–‡æ¡£](https://docs.sglang.ai/advanced_features/speculative_decoding.html)
### å·²çŸ¥é—®é¢˜
[SGLang issue #9888](https://github.com/sgl-project/sglang/issues/9888) æˆ– [SGLang issue #9521](https://github.com/sgl-project/sglang/issues/9521)
- æŠ¥é”™å‘ç”Ÿåœ¨ speculative decoding draft é˜¶æ®µçš„ cuda graph padding
- è§£å†³æ–¹æ³•:Â 
	1. åˆ‡æ¢æ¨ç†åç«¯ä¸º fa3 tritonã€‚è¯¥ bug ä»…å‘ç”Ÿåœ¨ flashInfer ã€‚
	2. è¦†ç›–æ›´å®½çš„ `--sglang-cuda-graph-bs` æ¥é¿å…æŸäº› batch size åš cuda graph padding
	3. ç¦ç”¨ cuda graphï¼ˆæ€§èƒ½æŸå¤±å¤ªå¤§ï¼Œä¸æ¨èï¼‰
	4. Noticeï¼šç¦ç”¨ cuda graph padding `--sglang-disable-cuda-graph-padding` ç›®å‰å¯¹ speculative decoding ä¸ç”Ÿæ•ˆã€‚å‚è€ƒ [SGLang cuda_graph_runner.py](tbd)
- å¦‚éœ€ debugï¼Œå¯å°è¯•å¼€å¯ slime çš„ `--debug-rollout-only` å‚æ•°ï¼Œæ¥æ’é™¤å‚æ•°æ›´æ–°æˆ–æ¨¡å‹ offload çš„å½±å“
```bash
# if speculative decoding has bug, this can help debug
--debug-rollout-only

# If flashInfer has bug with speculative decoding, use fa3 or triton instead
--sglang-attention-backend fa3

# If bug exists when cuda graph do padding, extend the cuda graph batch size
--sglang-cuda-graph-bs $(seq 1 32) $(seq 40 8 64) $(seq 80 16 160)

# Improve performance by enlarging running batch size limit
--sglang-max-running-requests 128
```
[SGLang issue #9481](https://github.com/sgl-project/sglang/issues/9481)
- è§£å†³æ–¹æ³•ï¼š
	1. åº”ç”¨æœ€æ–°çš„ sglang patchã€‚
	2. å‚è€ƒè¿™ä¸ª pr ä¿®æ”¹ sglang https://github.com/sgl-project/sglang/pull/9687 
[SGLang PR #9388](https://github.com/sgl-project/sglang/pull/9388)
- å¦‚æœä½¿ç”¨å¤–éƒ¨ draft model å‡ºç° illegal memory accessï¼Œå¯èƒ½æ˜¯ç”±äº draft model å’Œ target model çš„ context length ä¸åŒ¹é…å¯¼è‡´çš„ bugã€‚
- è¯·æ›´æ–° SGLang >= 0.5.1 æ¥åº”ç”¨è¿™ä¸ª PRã€‚ï¼ˆå¹¶æ›´æ–° `sgl-kernel`ï¼‰

#### Llama 3.1 8B EAGLE3 çš„é—®é¢˜ 
- **Context Length é™åˆ¶**ï¼š`sglang-EAGLE3-LLaMA3.1-Instruct-8B` draft model çš„ context length ä»…æ”¯æŒ 2048 tokensï¼Œå¯¼è‡´ target model çš„ context ä¹Ÿå¿…é¡»é™åˆ¶ä¸º 2048ã€‚ æ‰€ä»¥ç›®å‰éœ€è¦é™åˆ¶ prompt + response çš„æ€»é•¿åº¦ä¸èƒ½è¶…è¿‡ 2048 tokensã€‚

- **Draft Model è®­ç»ƒé™åˆ¶**ï¼šå½“å‰å®ç°ä¸æ”¯æŒ draft model æœ¬èº«çš„è®­ç»ƒï¼Œdraft model åªèƒ½ç”¨äºæ¨ç†ã€‚

- **æ€§èƒ½é—®é¢˜**ï¼šåœ¨å½“å‰é…ç½®ä¸‹ï¼Œspeculative decoding å¹¶æœªæä¾›æ€§èƒ½æ”¶ç›Šï¼Œç”šè‡³å¯èƒ½å‡ºç°è´Ÿæ”¶ç›Šã€‚