# å¿«é€Ÿä½¿ç”¨

æœ¬æ–‡æ¡£ä»æ­å»ºç¯å¢ƒå¼€å§‹ï¼Œåœ¨ä¸€å°æ—¶å†…å¸¦æ‚¨å¿«é€Ÿä¸Šæ‰‹ slimeï¼Œæ¶µç›–ç¯å¢ƒé…ç½®ï¼Œæ•°æ®å‡†å¤‡ï¼Œè®­ç»ƒå¯åŠ¨å’Œå…³é”®ä»£ç è§£æå’Œé­”æ”¹ã€‚

## åŸºç¡€ç¯å¢ƒæ­å»º

ç”±äº slime å¯èƒ½ä¼šåŒ…å«é’ˆå¯¹ sglang/megatron çš„ä¸´æ—¶è¡¥ä¸ï¼ˆpatchï¼‰ã€‚ä¸ºé¿å…æ½œåœ¨çš„ç¯å¢ƒé…ç½®é—®é¢˜ï¼Œå¼ºçƒˆå»ºè®®**ç”¨æˆ·ä½¿ç”¨æˆ‘ä»¬æä¾›çš„æœ€æ–° Docker é•œåƒ**ï¼Œå®ƒå·²é¢„ç½®å¥½æ‰€æœ‰ä¾èµ–ã€‚

### ç¡¬ä»¶æ”¯æŒè¯´æ˜

**slime** æ”¯æŒå¤šç§ NVIDIA GPU ç¡¬ä»¶å¹³å°ï¼š

- **B200 ç³»åˆ—**ï¼šå®Œå…¨æ”¯æŒï¼Œè¿è¡Œæ­¥éª¤ä¸ H ç³»åˆ—å®Œå…¨ç›¸åŒ
- **H ç³»åˆ— (H100/H200)**ï¼šå®˜æ–¹æ”¯æŒï¼Œå…·æœ‰å®Œæ•´çš„ CI æµ‹è¯•ä¿æŠ¤ï¼Œè¿è¡Œç¨³å®šå¯é 

**é‡è¦è¯´æ˜**ï¼š
- æœ€æ–°çš„ Docker é•œåƒå¯¹ B å¡å’Œ H å¡é€šç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®
- Megatron åç«¯åœ¨ H å¡ä¸Šå…·æœ‰ CI ä¿æŠ¤ï¼Œç»è¿‡å……åˆ†æµ‹è¯•éªŒè¯ï¼Œæ¨èç”Ÿäº§ç¯å¢ƒä½¿ç”¨
- B å¡åŸºæœ¬åŠŸèƒ½ç¨³å®šï¼Œå¯ä½œä¸ºå¼€å‘å’Œæµ‹è¯•å‚è€ƒï¼Œä½†æš‚æ—  CI ä¿æŠ¤
- ä¸¤ç§ç¡¬ä»¶å¹³å°ä½¿ç”¨å®Œå…¨ç›¸åŒçš„å®‰è£…å’Œå¯åŠ¨æµç¨‹

- å¯¹äºä¸æ–¹ä¾¿ä½¿ç”¨ docker çš„åœºæ™¯ï¼Œè¯·å‚è€ƒ [build_conda.sh](https://github.com/THUDM/slime/blob/main/build_conda.sh)ï¼›
- å¯¹äº AMD æ”¯æŒï¼Œè¯·å‚è€ƒ [AMD ä½¿ç”¨æ•™ç¨‹](../../en/platform_support/amd_tutorial.md)ã€‚

### æ‹‰å–å¹¶å¯åŠ¨ Docker å®¹å™¨

è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œæ‹‰å–æœ€æ–°é•œåƒå¹¶å¯åŠ¨ä¸€ä¸ªäº¤äº’å¼å®¹å™¨ï¼š

```shell
# æ‹‰å–æœ€æ–°é•œåƒ
docker pull slimerl/slime:latest

# å¯åŠ¨å®¹å™¨
docker run --rm --gpus all --ipc=host --shm-size=16g \
  --ulimit memlock=-1 --ulimit stack=67108864 \
  -it slimerl/slime:latest /bin/bash
```

### å®‰è£… slime

è¿›å…¥ Docker å®¹å™¨åï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å…‹éš† slime ä»“åº“å¹¶è¿›è¡Œå®‰è£…ï¼š

```bash
# è·¯å¾„å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
cd /root/
git clone https://github.com/THUDM/slime.git
cd slime
pip install -e .
```

## æ¨¡å‹ä¸æ•°æ®é›†ä¸‹è½½

å¯ä»¥ä» Hugging Faceã€ModelScope ç­‰å¹³å°ä¸‹è½½æ‰€éœ€çš„æ¨¡å‹å’Œæ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ `huggingface_hub` ä¸‹è½½ç¤ºä¾‹èµ„æºçš„å‘½ä»¤ï¼š

```bash

pip install -U huggingface_hub

# ä¸‹è½½æ¨¡å‹æƒé‡ (GLM-Z1-9B)
hf download zai-org/GLM-Z1-9B-0414 --local-dir /root/GLM-Z1-9B-0414

# ä¸‹è½½è®­ç»ƒæ•°æ®é›† (dapo-math-17k)
hf download --repo-type dataset zhuzilin/dapo-math-17k \
  --local-dir /root/dapo-math-17k

# ä¸‹è½½è¯„ä¼°æ•°æ®é›† (aime-2024)
hf download --repo-type dataset zhuzilin/aime-2024 \
  --local-dir /root/aime-2024
```

## æ¨¡å‹æƒé‡è½¬æ¢

### Hugging Face æ ¼å¼ è½¬æ¢ä¸º Megatron æ ¼å¼

å½“ä½¿ç”¨ Megatron ä½œä¸ºè®­ç»ƒåç«¯æ—¶ï¼Œéœ€è¦å…ˆå°† Hugging Face æ ¼å¼çš„æ¨¡å‹æƒé‡è½¬æ¢ä¸º Megatron `torch_dist` æ ¼å¼ã€‚

é¦–å…ˆï¼ŒåŠ è½½ç›®æ ‡æ¨¡å‹çš„é…ç½®æ–‡ä»¶ã€‚`slime/scripts/models` ç›®å½•ä¸‹åŒ…å«äº†æ”¯æŒæ¨¡å‹çš„é…ç½®æ–‡ä»¶ã€‚éœ€è¦ `source` å¯¹åº”æ¨¡å‹çš„è„šæœ¬ï¼Œå°†é…ç½®å‚æ•°åŠ è½½åˆ°å½“å‰ç¯å¢ƒä¸­ã€‚æ­¤å¤„æˆ‘ä»¬ä»¥ GLM4-9B æ¨¡å‹ä¸ºä¾‹å­ï¼Œå¯¹äº Qwen3-4Bï¼ŒQwen3-30B-A3Bï¼Œæ˜¯ç±»ä¼¼çš„ã€‚

```bash
cd /root/slime
source scripts/models/glm4-9B.sh
```

æ¥ä¸‹æ¥ï¼Œè¿è¡Œè½¬æ¢è„šæœ¬ã€‚è¯·æ³¨æ„ä»¥ä¸‹å‚æ•°ï¼š
- `--hf-checkpoint`: æŒ‡å®šå·²ä¸‹è½½çš„ Hugging Face æ¨¡å‹æƒé‡è·¯å¾„ã€‚
- `--save`: æŒ‡å®šè½¬æ¢å `torch_dist` æ ¼å¼æƒé‡çš„ä¿å­˜è·¯å¾„ã€‚

```bash
PYTHONPATH=/root/Megatron-LM python tools/convert_hf_to_torch_dist.py \
    ${MODEL_ARGS[@]} \
    --hf-checkpoint /root/GLM-Z1-9B-0414 \
    --save /root/GLM-Z1-9B-0414_torch_dist
```

å¯¹äºæ›´å¤§çš„æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ `torchrun` æ¥å¯åŠ¨è½¬æ¢è„šæœ¬ï¼Œä»è€Œä½¿ç”¨å¤šå¼  GPU ç”šè‡³å¤šæœºè¿›è¡Œæƒé‡è½¬æ¢ã€‚
æ³¨æ„ï¼škimi-k2æ¨¡å‹æƒé‡è½¬æ¢æ—¶ï¼Œéœ€æ‰“å¼€æ¨¡å‹è·¯å¾„ä¸­çš„config.jsonï¼Œå°†"model_type": "kimi_k2"ä¿®æ”¹ä¸º"model_type": "deepseek_v3"ã€‚

### Megatron æ ¼å¼ è½¬æ¢ä¸º Hugging Face æ ¼å¼

å¯ä»¥é€šè¿‡è¿™æ ·çš„æ–¹å¼å°†è®­ç»ƒè¿‡ç¨‹ä¸­ä¿å­˜çš„ Megatron æ ¼å¼çš„æƒé‡è½¬æ¢å› Huggingface æ ¼å¼ï¼š

```bash
PYTHONPATH=/root/Megatron-LM python tools/convert_torch_dist_to_hf.py \
  --input-dir /path/to/torch_dist_ckpt/iter_xxx/ \
  --output-dir /root/GLM-Z1-9B-0414-iter_xxx \
  --origin-hf-dir /root/GLM-Z1-9B-0414
```

ç”±äº Megatron ä¼šå¯¹ embedding åš paddingï¼Œå¯èƒ½ä¼šå‡ºç°è½¬æ¢å‡ºæ¥çš„æƒé‡çš„ embedding å½¢çŠ¶ä¸åŒ¹é…çš„é—®é¢˜ã€‚è¿™æ—¶éœ€è¦åœ¨è½¬æ¢æ—¶è®¾ç½® `--vocab-size`ã€‚

å¯¹äºä½¿ç”¨ FSDP åç«¯è®­ç»ƒå¹¶ä¿å­˜çš„æ£€æŸ¥ç‚¹ï¼ˆç›®å½•ä¸­æ²¡æœ‰ `common.pt` çš„æƒ…å†µï¼‰ï¼Œè¯·ä½¿ç”¨ä¸“é—¨çš„è½¬æ¢è„šæœ¬ã€‚å°† `--input-dir` æŒ‡å‘æ£€æŸ¥ç‚¹ç›®å½•ï¼ˆä¾‹å¦‚ `iter_xxx` æˆ– `iter_xxx/model`ï¼‰ï¼Œå¹¶æä¾›åŸå§‹ Hugging Face æ¨¡å‹è·¯å¾„ï¼š

```bash
python tools/convert_fsdp_to_hf.py \
  --input-dir /path/to/fsdp_ckpt/iter_xxx \
  --output-dir /root/fsdp-converted \
  --origin-hf-dir /root/GLM-Z1-9B-0414
```

## è®­ç»ƒè„šæœ¬ä¸å‚æ•°æ¦‚è§ˆ

å®Œæˆä¸Šè¿°å‡†å¤‡å·¥ä½œåï¼Œå³å¯è¿è¡Œè®­ç»ƒè„šæœ¬ã€‚

```bash
cd /root/slime
bash scripts/run-glm4-9B.sh
```

æˆ‘ä»¬è¿˜æ˜¯ä»¥ run-glm4-9B.sh è„šæœ¬ä¸ºä¾‹ï¼Œç®€å•åˆ†æä¸»è¦å‚æ•°çš„ä½œç”¨ã€‚

### MODEL_ARGS: æ¨¡å‹é…ç½®å‚æ•°

```bash
SCRIPT_DIR="$(cd -- "$(dirname -- "${BASH_SOURCE[0]}")" &>/dev/null && pwd)"
source "${SCRIPT_DIR}/models/glm4-9B.sh"
```

æ­¤éƒ¨åˆ†é€šè¿‡ `source` å‘½ä»¤ä» `scripts/models/glm4-9B.sh` æ–‡ä»¶ä¸­åŠ è½½æ¨¡å‹é…ç½®ã€‚è¿™äº›é…ç½®å‡ä¸º Megatron æ‰€éœ€çš„è¶…å‚æ•°ã€‚ç”±äº Megatron æ— æ³•ç›´æ¥ä»æ£€æŸ¥ç‚¹ï¼ˆcheckpointï¼‰ä¸­è¯»å–æ¨¡å‹é…ç½®ï¼Œå› æ­¤éœ€è¦æ‰‹åŠ¨æŒ‡å®šã€‚æˆ‘ä»¬åœ¨ `scripts/models/` ç›®å½•ä¸‹æä¾›äº†ä¸€äº›å¸¸ç”¨æ¨¡å‹çš„é…ç½®ç¤ºä¾‹ã€‚

> âš ï¸ **æ³¨æ„**ï¼š
> è¯·åŠ¡å¿…æ£€æŸ¥æ¨¡å‹é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°ï¼ˆå¦‚ `--rotary-base`ï¼‰æ˜¯å¦ä¸æ‚¨å½“å‰ä½¿ç”¨çš„æ¨¡å‹å®Œå…¨åŒ¹é…ã€‚åŒä¸€æ¨¡å‹ç»“æ„çš„ä¸åŒç‰ˆæœ¬å¯èƒ½ä½¿ç”¨ä¸åŒçš„é…ç½®å€¼ã€‚å¦‚æœéœ€è¦ä¿®æ”¹ï¼Œæ‚¨å¯ä»¥åœ¨ `source` ä¹‹åç›´æ¥è¦†ç›–ï¼Œä¾‹å¦‚ï¼š
> ```bash
> source "${SCRIPT_DIR}/models/glm4-9B.sh"
> MODEL_ARGS+=(--rotary-base 10000)
> ```

### CKPT_ARGS: æ£€æŸ¥ç‚¹ä¸è·¯å¾„å‚æ•°

```bash
CKPT_ARGS=(
   # ç”¨äºåŠ è½½ tokenizer ç­‰å…¶ä»–ä¿¡æ¯ï¼Œå®é™…ä¸Šä¸ä¼šä½¿ç”¨ hf è·¯å¾„ä¸­çš„æ¨¡å‹æƒé‡å‚æ•°
   --hf-checkpoint /root/GLM-Z1-9B-0414
   # å‚è€ƒæ¨¡å‹ (Reference Model) çš„ Megatron æ ¼å¼æ£€æŸ¥ç‚¹
   --ref-load /root/GLM-Z1-9B-0414_torch_dist
   # Actor æ¨¡å‹çš„åŠ è½½è·¯å¾„ã€‚è‹¥ä¸ºç©ºæˆ–ä¸å­˜åœ¨æœ‰æ•ˆçš„checkpointï¼Œåˆ™ä» --ref-load åŠ è½½
   --load /root/GLM-Z1-9B-0414_slime/
   # è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹çš„ä¿å­˜è·¯å¾„
   --save /root/GLM-Z1-9B-0414_slime/
   # æ¨¡å‹ä¿å­˜é—´éš”ï¼ˆæ­¥æ•°ï¼‰
   --save-interval 20
)
```

### ROLLOUT_ARGS: æ•°æ®ç”Ÿæˆï¼ˆRolloutï¼‰å‚æ•°

æ•´ä¸ªè®­ç»ƒæµç¨‹å¯è§†ä¸ºä¸€ä¸ª **â€œæ•°æ®é‡‡æ · â†’ æƒé‡æ›´æ–°â€** çš„é—­ç¯ã€‚

**é˜¶æ®µä¸€ï¼šæ•°æ®é‡‡æ · (Rollout)**
- `--rollout-batch-size`ï¼šå®šä¹‰æ¯è½®é‡‡æ ·çš„ **Prompt æ•°é‡**
- `--n-samples-per-prompt`ï¼šå®šä¹‰æ¯ä¸ª Prompt ç”Ÿæˆçš„ **å›å¤æ•°é‡** (ç”¨äº GRPO ç±»ä¼¼ç®—æ³•)

> ä¸¤è€…ç›¸ä¹˜ï¼Œå†³å®šäº† **å•è½®é‡‡æ ·äº§ç”Ÿçš„æ€»æ ·æœ¬æ•°**ã€‚

**é˜¶æ®µäºŒï¼šæ¨¡å‹è®­ç»ƒ (Training)**
- `--global-batch-size`ï¼šå®šä¹‰ **æ‰§è¡Œä¸€æ¬¡å‚æ•°æ›´æ–°ï¼ˆoptimizer.stepï¼‰** æ‰€éœ€çš„æ ·æœ¬é‡
- `--num-steps-per-rollout`ï¼šå®šä¹‰ä½¿ç”¨å½“å‰é‡‡æ ·æ•°æ®ï¼Œ**æ€»å…±æ‰§è¡Œå¤šå°‘æ¬¡å‚æ•°æ›´æ–°**  (æˆ‘ä»¬é»˜è®¤ä¸º 1ï¼Œä½¿ç”¨ on-policy è®­ç»ƒ)

> ä¸¤è€…ç›¸ä¹˜ï¼Œå†³å®šäº† **å•è½®è®­ç»ƒæ¶ˆè€—çš„æ€»æ ·æœ¬æ•°**ã€‚

> âš ï¸ è¿™é‡Œçš„ **å‚æ•°æ›´æ–°** æŒ‡è®­ç»ƒç¯èŠ‚çš„ optimizer.step()ï¼Œä¸åŒäºè®­ç»ƒå¼•æ“å‘æ¨ç†å¼•æ“å‘èµ·çš„æƒé‡åŒæ­¥(Weight Sync)ã€‚

åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¯è½®çš„â€œäº§å‡ºâ€ä¸â€œæ¶ˆè€—â€å¿…é¡»ç›¸ç­‰ï¼Œéµå¾ªä»¥ä¸‹çº¦æŸï¼š
**`(rollout-batch-size Ã— n-samples-per-prompt) = (global-batch-size Ã— num-steps-per-rollout)`**

- åœ¨ slime ä¸­ï¼Œå¦‚æœè®¾ç½®äº† `--num-steps-per-rollout` ï¼Œ`--global-batch-size` æœªè®¾ç½®åˆ™ä¼šè¢«è‡ªåŠ¨è®¾ç½®ï¼Œè®¾ç½®äº†åˆ™ä¼šè¢«ç”¨ä¸Šè¿°å…¬å¼æ ¡éªŒã€‚

**è®­ç»ƒæµç¨‹æ¬¡æ•°æ§åˆ¶**
-   `--num-rollout`: æ§åˆ¶æ•´ä¸ª **â€œé‡‡æ ·â†’è®­ç»ƒâ€** å¾ªç¯çš„**æ€»æ‰§è¡Œè½®æ¬¡**ã€‚

```bash
ROLLOUT_ARGS=(
   # Prompt æ•°æ®é›†ï¼ŒJSONL æ ¼å¼
   --prompt-data /root/dapo-math-17k/dapo-math-17k.jsonl
   --input-key prompt
   --label-key label
   # è‹¥ Prompt çš„ `input_key` æ˜¯ OpenAI message æ ¼å¼ï¼Œåˆ™åº”ç”¨ Chat Template
   --apply-chat-template
   # æ˜¯å¦åœ¨ Rollout é˜¶æ®µæ‰“ä¹±æ•°æ®
   --rollout-shuffle

   # Reward Model ç±»å‹ã€‚slime å†…ç½®å¤šç§ç±»å‹ï¼Œä¹Ÿæ”¯æŒé€šè¿‡ --custom-rm-path è‡ªå®šä¹‰
   --rm-type deepscaler

   # è¿™äº”ä¸ªå‚æ•°æ¥æ§åˆ¶ rollout ä¸ train çš„å…³ç³»
   --num-rollout 3000
   --rollout-batch-size 16
   --n-samples-per-prompt 8
   --num-steps-per-rollout 1
   --global-batch-size 128

   # Rollout é‡‡æ ·å‚æ•°
   --rollout-max-response-len 8192
   --rollout-temperature 0.8

   # å¯¹ rollout é˜¶æ®µæ”¶é›†çš„æ•°æ®è¿›è¡Œè´Ÿè½½å‡è¡¡ã€‚å®ƒç¡®ä¿äº†åˆ†é…åˆ°æ¯ä¸ªè®­ç»ƒè¿›ç¨‹ï¼ˆDP rankï¼‰çš„è®¡ç®—ä»»åŠ¡é‡å¤§è‡´ç›¸ç­‰ï¼Œå¯èƒ½å¯¹è®­ç»ƒé€Ÿåº¦æœ‰å¥½å¤„
   --balance-data
)
```

### EVAL_ARGS: è¯„ä¼°å‚æ•°

è¯„ä¼°è¿‡ç¨‹ä¼šç»§æ‰¿å¤§éƒ¨åˆ† Rollout å‚æ•°ï¼Œä½†æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‚æ•°è¿›è¡Œè¦†ç›–ï¼Œä»¥å®ç°ä¸è®­ç»ƒä¸åŒçš„è¯„ä¼°ç­–ç•¥ã€‚

```bash
EVAL_ARGS=(
   # è¯„ä¼°é—´éš”ï¼ˆRollout æ•°ï¼‰
   --eval-interval 5
   # è¯„ä¼°ç”¨çš„ Prompt æ•°æ®é›†
   --eval-prompt-data aime /root/aime-2024/aime-2024.jsonl
   # æ¯ä¸ªè¯„ä¼° Prompt çš„é‡‡æ ·æ•°é‡
   --n-samples-per-eval-prompt 16
   # è¯„ä¼°æ—¶æœ€å¤§å“åº”é•¿åº¦
   --eval-max-response-len 16384
   # è¯„ä¼°æ—¶é‡‡æ ·å‚æ•°
   --eval-top-p 0.7
)
```

### PERF_ARGS: æ€§èƒ½ä¸å¹¶è¡Œå‚æ•°

è¿™éƒ¨åˆ†ä¸»è¦åŒ…å« Megatron çš„å¹¶è¡Œé…ç½®ã€‚`--use-dynamic-batch-size` å’Œ `--max-tokens-per-gpu` æ˜¯ slime æ·»åŠ çš„ç‰¹æœ‰ä¼˜åŒ–ã€‚

-   `--max-tokens-per-gpu`: æ¯å¼  GPU å¤„ç†çš„æœ€å¤§ Token æ•°ã€‚å¯ç”¨åŠ¨æ€æ‰¹å¤„ç†ï¼ˆ`use_dynamic_batch_size`ï¼‰åï¼Œç³»ç»Ÿä¼šæ™ºèƒ½åœ°å°†é•¿çŸ­ä¸ä¸€çš„æ ·æœ¬æ‰“åŒ…ï¼Œä½¿æ¯ä¸ª micro-batch çš„æ€» Token æ•°æ¥è¿‘æ­¤é™åˆ¶ï¼Œä»è€Œæå‡è®­ç»ƒæ•ˆç‡ã€‚å¦‚æœå•ä¸ªæ ·æœ¬é•¿åº¦è¶…è¿‡è¯¥å€¼ï¼Œå®ƒå°†ç‹¬ç«‹å½¢æˆä¸€ä¸ª batchã€‚åœ¨ä¸Šä¸‹æ–‡å¹¶è¡Œï¼ˆCPï¼‰æ¨¡å¼ä¸‹ï¼Œ`N` å¼  CP å¡å…±äº« `N * max_tokens_per_gpu` çš„æ€»é•¿åº¦ã€‚
-   `--use-dynamic-batch-size`: å¯ç”¨åŠ¨æ€æ‰¹å¤„ç†ã€‚æ­¤æ—¶ä¼šå¿½ç•¥ `--micro-batch-size`ã€‚


> ğŸ’¡ **æç¤º**ï¼š
>  slime æ€»æ˜¯ä¼šé€šè¿‡ data packing çš„æ–¹æ³•è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä¸”ä¸¥æ ¼ä¿è¯ per sample loss æˆ– per token loss æ˜¯æ­£ç¡®çš„ã€‚å› æ­¤ï¼Œå¼€å¯ dynamic batch size ä¸ä¼šå¯¹ loss è®¡ç®—æœ‰å½±å“ï¼Œå¼ºçƒˆæ¨èå¼€å¯ã€‚

```bash
PERF_ARGS=(
   --tensor-model-parallel-size 2
   --sequence-parallel
   --pipeline-model-parallel-size 1
   --context-parallel-size 2
   --expert-model-parallel-size 1
   --expert-tensor-parallel-size 1

   --recompute-granularity full
   --recompute-method uniform
   --recompute-num-layers 1

   # --micro-batch-size 1 # å¯ç”¨åŠ¨æ€æ‰¹å¤„ç†åæ­¤é¡¹è¢«å¿½ç•¥
   --use-dynamic-batch-size
   --max-tokens-per-gpu 4608
)
```

### GRPO_ARGS: GRPO ç®—æ³•å‚æ•°

-   `--use-kl-loss`: å¯ç”¨æ­¤é€‰é¡¹å°†åŠ è½½ä¸€ä¸ªå‚è€ƒæ¨¡å‹ï¼ˆReference Modelï¼‰ï¼Œå¹¶è®¡ç®—å½“å‰æ¨¡å‹ä¸å‚è€ƒæ¨¡å‹ä¹‹é—´çš„ KL æ•£åº¦ï¼ˆKL Divergenceï¼‰ä½œä¸ºä¸€é¡¹ç›‘æ§æŒ‡æ ‡ã€‚KL æ•£åº¦æ˜¯å¦è¢«è®¡å…¥æœ€ç»ˆçš„è®­ç»ƒæŸå¤±ï¼ˆLossï¼‰ï¼Œå–å†³äº `--kl-loss-coef` å‚æ•°ã€‚è‹¥è¯¥å‚æ•°è®¾ç½®ä¸º 0ï¼Œåˆ™ KL æ•£åº¦ä»…ä½œä¸ºè§‚æµ‹æŒ‡æ ‡æ˜¾ç¤ºï¼Œè€Œä¸ä¼šå‚ä¸æŸå¤±è®¡ç®—ã€‚

```bash
GRPO_ARGS=(
   --advantage-estimator grpo
   --use-kl-loss
   --kl-loss-coef 0.00
   --kl-loss-type low_var_kl
   --entropy-coef 0.00
   --eps-clip 0.2
   --eps-clip-high 0.28
)
```

- `--advantage-estimator`: é™¤å» [GRPO](https://arxiv.org/abs/2402.03300)ï¼Œslime è¿˜æ”¯æŒä¸°å¯Œçš„å…¶ä»–è®­ç»ƒç®—æ³•ï¼Œä¾‹å¦‚ [GSPO](https://arxiv.org/abs/2507.18071)ã€[Reinforce++](https://arxiv.org/abs/2501.03262) ä¸ [Reinforce++ Baseline](https://arxiv.org/abs/2501.03262)ã€ä»¥åŠ [PPO](https://arxiv.org/abs/1707.06347)ï¼›
- `--calculate-per-token-loss`ï¼šslime ä¸­é»˜è®¤çš„æ–¹æ¡ˆæ˜¯ per sample lossï¼Œå³ `mean(sum(sample_i) / len(sample_i))`ï¼Œå¦‚æœéœ€è¦è®¡ç®— per token lossï¼Œå³ `sum(sum(sample_i)) / sum(len(sample_i))`ï¼Œå¯ä»¥å¼€å¯ `--calculate-per-token-loss`ï¼›
- `--use-tis`ï¼šå¦‚æœéœ€è¦å¼€å¯ TIS (Truncated Importance Sampling)ï¼Œå¯ä»¥å¼€å¯è¿™ä¸€è®¾ç½®ã€‚TIS ç”±æ­¤[åšå®¢](https://fengyao.notion.site/off-policy-rl)ä»‹ç»ã€‚

### OPTIMIZER_ARGS: ä¼˜åŒ–å™¨å‚æ•°

```bash
OPTIMIZER_ARGS=(
   --optimizer adam
   --lr 1e-6
   --lr-decay-style constant
   --weight-decay 0.1
   --adam-beta1 0.9
   --adam-beta2 0.98
)
```

### SGLANG_ARGS: SGLang æœåŠ¡å‚æ•°

è¿™éƒ¨åˆ†å‚æ•°ç”¨äºé…ç½® SGLang æ¨ç†æœåŠ¡ã€‚
- `--rollout-num-gpus-per-engine`: åŸºæœ¬ç­‰åŒäº SGLang çš„ `tp_size`ã€‚
- å…¶ä»– SGLang å‚æ•°å¯ä»¥é€šè¿‡æ·»åŠ  `--sglang-` å‰ç¼€ä¼ é€’ç»™ slime,  slime ä¼šè‡ªåŠ¨é€ä¼ ç»™ SGLangã€‚ä¾‹å¦‚ï¼Œè¦è®¾ç½® SGLang çš„ `--log-level INFO` å‚æ•°ï¼Œåªéœ€ä½¿ç”¨ `--sglang-log-level INFO` å³å¯ã€‚

> âš ï¸ **æ³¨æ„**ï¼š
> slime ä½¿ç”¨ `sgl-router` è°ƒåº¦å¤šä¸ª SGLang Serverã€‚åœ¨ä¸å¼€å¯ DP Attention çš„æƒ…å†µä¸‹ï¼Œ `dp_size` ä¼šé€šè¿‡ `rollout-num-gpus / rollout-num-gpus-per-engine` è®¡ç®—å¾—åˆ°ã€‚

```bash
SGLANG_ARGS=(
   --rollout-num-gpus-per-engine 2
)
```

## ç‰¹æ€§ä»‹ç»

### Colocated Actor and Rollout

åœ¨é»˜è®¤çš„é…ç½®ä¸‹ï¼Œè®­ç»ƒï¼ˆActorï¼‰å’Œæ¨ç†ï¼ˆRolloutï¼‰çš„èµ„æºæ˜¯åˆ†å¼€æŒ‡å®šçš„ï¼Œé€šè¿‡ ray ç»™è®­ç»ƒéƒ¨åˆ†åˆ†é… `actor_num_nodes * actor_num_gpus_per_node` å¼  GPUï¼Œç»™æ¨ç†åˆ†é… `rollout_num_gpus` å¼  GPUï¼Œä¹Ÿå³è®­æ¨åˆ†ç¦»ã€‚

**æ ‡å‡†ï¼ˆåˆ†ç¦»ï¼‰é…ç½®**ï¼š
```bash
ray job submit ... \
   -- python3 train.py \
   --actor-num-nodes 1 \
   --actor-num-gpus-per-node 4 \
   --rollout-num-gpus 4 \
   ...
```
ä¸Šè¿°é…ç½®ä¸­ï¼ŒActor ä½¿ç”¨ 4 å¼ å¡ï¼ŒRollout ä¹Ÿä½¿ç”¨ 4 å¼ å¡ï¼Œä¸¤è€…å¹¶è¡Œè¿è¡Œã€‚

**è®­æ¨ä¸€ä½“åŒ–ï¼ˆColocatedï¼‰é…ç½®**ï¼š
è¦å°†è®­ç»ƒå’Œæ¨ç†éƒ¨ç½²åœ¨åŒä¸€ç»„ GPU ä¸Šï¼Œè¯·æ·»åŠ  `--colocate` å‚æ•°ï¼Œå¼€å¯åä¼šå¿½ç•¥ `--rollout-num-gpus` è®©è®­ç»ƒå’Œæ¨ç†çš„å¡æ•°ç›¸ç­‰ã€‚


```bash
ray job submit ... \
   -- python3 train.py \
   --actor-num-nodes 1 \
   --actor-num-gpus-per-node 8 \
   --colocate \
   ...
```
æ­¤æ—¶ï¼Œè®­ç»ƒå’Œæ¨ç†å°†å…±äº«å…¨éƒ¨ 8 å¼  GPUã€‚

> âš ï¸ **æ³¨æ„**ï¼š
> åœ¨è®­æ¨ä¸€ä½“åŒ–æ¨¡å¼ä¸‹ï¼ŒMegatron åˆå§‹åŒ–åæ‰èƒ½è¢« offload æ‰ï¼Œä¼šå æ®ä¸€å®šé‡çš„æ˜¾å­˜ã€‚æ‚¨éœ€è¦é€šè¿‡è°ƒæ•´ `--sglang-mem-fraction-static` å‚æ•°æ¥é™ä½ SGLang çš„æ˜¾å­˜å ç”¨æ¯”ä¾‹ï¼Œä»¥é¿å…æ˜¾å­˜ä¸è¶³ã€‚é€šå¸¸æˆ‘ä»¬å»ºè®®ä¸º 0.8ã€‚

> æ­¤å¤–ï¼Œ[torch_memory_saver](https://github.com/fzyzcjy/torch_memory_saver) é‡Œé¢çš„ä¸€äº›ä¼˜åŒ–åªèƒ½åœ¨è®­æ¨ä¸€ä½“æ¨¡å¼ä¸­ä½¿ç”¨ï¼Œå› ä¸ºéœ€è¦é‡Šæ”¾ GPU æ˜¾å­˜ã€‚è®­æ¨åˆ†ç¦»æ¨¡å¼æš‚ä¸æ”¯æŒã€‚

### Dynamic Sampling

slime æ”¯æŒæ›´å¤æ‚çš„é‡‡æ ·ç­–ç•¥ï¼Œä¾‹å¦‚ [DAPO](https://dapo-sia.github.io/) ä¸­ä½¿ç”¨çš„åŠ¨æ€é‡‡æ ·ã€‚è¦å¯ç”¨æ­¤åŠŸèƒ½ï¼Œéœ€é…ç½®ä»¥ä¸‹å‚æ•°ï¼š

```bash
   --over-sampling-batch-size 64 \
   --dynamic-sampling-filter-path \
     slime.rollout.filter_hub.dynamic_sampling_filters.check_reward_nonzero_std
```

è¿™é‡Œ `over_sampling_batch_size` éœ€è¦å¤§äº `rollout_batch_size`ï¼Œä¾‹å¦‚é…ç½®ä¸ºï¼š

```bash
   --rollout-batch-size 32 \
   --n-samples-per-prompt 8 \
   --over-sampling-batch-size 64 \
```

é‚£ä¹ˆ sampling ä¼šç›´æ¥é‡‡æ · 64 æ¡ promptï¼Œæ¯æ¡ prompt é‡‡æ · 8 æ¬¡ã€‚å› ä¸º slime å†…éƒ¨è¿›è¡Œçš„æ˜¯å¼‚æ­¥é‡‡æ ·ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼šå…ˆåè·å¾—æ¯ä¸ª prompt çš„ 8 æ¡å›å¤ã€‚åœ¨æ”¶åˆ°å›å¤æ—¶ï¼Œä¼šç”¨ `dynamic_sampling_filter_path` å¯¹åº”çš„å‡½æ•°è¿›è¡Œç­›é€‰ï¼Œå¦‚æœé€šè¿‡ï¼Œåˆ™ç•™ä¸‹è¿™ 8 æ¡æ•°æ®ï¼Œå¦åˆ™åˆ™ä¸¢æ‰ã€‚

ç¤ºä¾‹ä¸­çš„è¿‡æ»¤å‡½æ•° `check_reward_nonzero_std` ä¼šæ£€æŸ¥ä¸€ç»„æ ·æœ¬çš„å¥–åŠ±ï¼ˆrewardï¼‰æ ‡å‡†å·®æ˜¯å¦å¤§äºé›¶ï¼Œç¡®ä¿ç•™ä¸‹çš„æ¯ç»„æ ·æœ¬å…¶å¥–åŠ±åˆ†æ•°éƒ½å­˜åœ¨å·®å¼‚ï¼Œä»è€Œé¿å…æ•°æ®è¿‡äºå•ä¸€ï¼Œæå‡äº†æ•°æ®çš„å¤šæ ·æ€§ã€‚

```python
def check_reward_nonzero_std(args, samples: list[Sample], **kwargs):
    rewards = [sample.reward for sample in samples]
    return torch.tensor(rewards, dtype=torch.float).std() > 0.0
```

å¦‚æœè¿‡æ»¤å‡½æ•°éå¸¸ä¸¥æ ¼ï¼Œå¯¼è‡´å¤§é‡ prompt ç»„è¢«ä¸¢å¼ƒï¼Œç³»ç»Ÿä¼šç›‘æ§ ` remaining_batch_size` ä¸­å¾…å¤„ç†çš„ä»»åŠ¡æ•°é‡ã€‚ä¸€æ—¦å¾…å¤„ç†çš„ä»»åŠ¡æ•°å› ä¸¢å¼ƒè¿‡å¤šè€Œé™è‡³ç›®æ ‡æ•° (32) ä»¥ä¸‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è§¦å‘æ–°ä¸€è½®çš„è¿‡é‡‡æ ·ï¼Œå†æ¬¡è¯·æ±‚  `over_sampling_batch_size` (64) ä¸ªæ–°çš„ prompt é‡å¤ä¸Šè¿°æµç¨‹ã€‚

### Partial Rollout

åœ¨åŠ¨æ€é‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œå¤§é‡è¯·æ±‚å¯èƒ½ä¼šè¢«æå‰ä¸­æ­¢ï¼ˆabortï¼‰ï¼Œé€ æˆè®¡ç®—èµ„æºæµªè´¹ã€‚é€šè¿‡å¯ç”¨ `--partial-rollout` å‚æ•°ï¼Œå¯ä»¥å°†è¿™äº›ç”Ÿæˆåˆ°ä¸€åŠçš„æ ·æœ¬ç¼“å­˜èµ·æ¥ï¼Œåœ¨ä¸‹ä¸€ä¸ª Rollout é˜¶æ®µç»§ç»­ç”Ÿæˆï¼Œä»è€Œæå‡æ€§èƒ½ã€‚

æ‚¨è¿˜å¯ä»¥é€šè¿‡ `--buffer-filter-path` è‡ªå®šä¹‰ä»ç¼“å­˜ä¸­æå–æ•°æ®çš„ç­–ç•¥ã€‚é»˜è®¤ç­–ç•¥æ˜¯ `pop_first`ï¼Œå³æŒ‰å…ˆè¿›å…ˆå‡ºçš„é¡ºåºæå–æ‰€éœ€æ•°é‡çš„æ ·æœ¬ã€‚

```python
def pop_first(args, rollout_id, buffer: list[list[Sample]], num_samples: int) -> list[list[Sample]]:
    num_to_pop = min(len(buffer), num_samples)
    samples = buffer[:num_to_pop]
    del buffer[:num_to_pop]
    return samples
```

å³æ¯æ¬¡å–å‡ºå‰ `num_samples` ä¸ª prompt å¯¹åº”çš„ `num_samples * n_samples_per_prompt` æ¡æ•°æ®ã€‚

> ğŸ’¡ **æç¤º**ï¼š
> æ¯æ¡ partial rollout sample çš„ `sample.metadata` ä¸­å­˜å‚¨äº†ç¬¬ä¸€æ¬¡è¿›è¡Œç”Ÿæˆçš„ rollout idï¼Œå¯ä»¥ç”¨äºæ•°æ®è¿‡æ»¤ã€‚



### bf16 è®­ç»ƒ fp8 æ¨ç†

slime ç›´æ¥æ”¯æŒ bf16 è®­ç»ƒï¼Œfp8 æ¨ç†ã€‚å¯¹äº Qwen3-4B æ¨¡å‹ï¼Œåªéœ€è¦ä¸‹è½½å¦‚ä¸‹æ¨¡å‹ï¼š

```bash
hf download Qwen/Qwen3-4B-FP8 --local-dir /root/Qwen3-4B-FP8
```

å¹¶å°† `--hf-checkpoint` æ›¿æ¢ä¸ºï¼š

```bash
   # ç”¨äºåŠ è½½ tokenizer ç­‰å…¶ä»–ä¿¡æ¯ï¼Œå®é™…ä¸Šä¸ä¼šä½¿ç”¨ hf è·¯å¾„ä¸­çš„æ¨¡å‹æƒé‡å‚æ•°
   --hf-checkpoint /root/Qwen3-4B-FP8

   #  megatron checkpoint è¿˜éœ€è¦æ˜¯æœ€å¼€å§‹ç”¨ bf16 çš„ huggingface è½¬æ¢çš„ dist æƒé‡ï¼Œä¸å› ä¸º FP8 rollout è€Œå»åšä¿®æ”¹ã€‚
   --ref-load /root/Qwen3-4B_torch_dist
```

å³å¯è§¦å‘ fp8 æ¨ç†ã€‚ç›®å‰æˆ‘ä»¬ä¼šå°† bf16 æƒé‡ç›´æ¥ cast ä¸º fp8ï¼Œåç»­ä¼šé€æ¸æ·»åŠ å¯¹ç²¾åº¦å½±å“æ›´å°çš„é‡åŒ–æ–¹æ¡ˆã€‚

âš ï¸  è®­ç»ƒçš„ megatron checkpoint è¿˜éœ€è¦æ˜¯æœ€å¼€å§‹ç”¨ bf16 çš„ huggingface è½¬æ¢çš„ã€‚


## Multiturn é€‚é…

slime æ¡†æ¶é«˜åº¦å¯æ‰©å±•ï¼Œæ”¯æŒå¤æ‚çš„ Agent åœºæ™¯ï¼ˆå¦‚å¤šè½®äº¤äº’ä¸å·¥å…·è°ƒç”¨ï¼‰ã€‚å…¶æ ¸å¿ƒæœºåˆ¶æ˜¯é€šè¿‡è‡ªå®šä¹‰å‡½æ•°ï¼Œé‡å†™é»˜è®¤çš„æ•°æ®ç”Ÿæˆ (Rollout) ä¸å¥–åŠ±è®¡ç®— (Reward) é€»è¾‘ã€‚

æœ¬éƒ¨åˆ†ä»¥ä¸€ä¸ªåŸºäº [Search-R1](https://github.com/PeterGriffinJin/Search-R1) çš„å®ç°ä¸ºä¾‹ï¼Œè¯´æ˜å¦‚ä½•é€‚é… slime ä»¥æ”¯æŒå¤šè½®äº¤äº’ã€‚

### é€‚é…æ€è·¯æ€»ç»“

é€‚é… slime ä»¥æ”¯æŒå¤šè½®äº¤äº’ä¸»è¦åŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼š

1.  **æ•°æ®å‡†å¤‡**ï¼šå°†å¤šè½®äº¤äº’æ•°æ®é›†é€‚é…ä¸º slime çš„ `Sample` å¯¹è±¡ã€‚å°†å¯¹è¯å†å²ã€çœŸå®æ ‡ç­¾ç­‰æ˜ å°„åˆ° `prompt` å’Œ `label` å­—æ®µï¼Œå¹¶å°†å·¥å…·å®šä¹‰ã€ä¸­é—´çŠ¶æ€ç­‰é¢å¤–ä¿¡æ¯å­˜å…¥ `metadata` å­—æ®µï¼Œä¾›åç»­å‡½æ•°è°ƒç”¨ã€‚

2.  **å®ç°è‡ªå®šä¹‰ç”Ÿæˆå‡½æ•°**ï¼šç¼–å†™å‡½æ•°æ¨¡æ‹Ÿâ€œæ¨¡å‹ç”ŸæˆåŠ¨ä½œ â†’ æ‰§è¡Œå·¥å…· â†’ æ‹¼æ¥è§‚å¯Ÿç»“æœâ€çš„äº¤äº’å¾ªç¯ï¼Œå¹¶æ­£ç¡®å¤„ç† Loss Maskingã€‚

3.  **å®ç°è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°**ï¼šç¼–å†™å‡½æ•°è¯„ä¼°å®Œæ•´çš„äº¤äº’è½¨è¿¹ï¼Œè¿”å›æœ€ç»ˆçš„å¥–åŠ±åˆ†æ•°ã€‚

### æ•°æ®å‡†å¤‡ä¸æ˜ å°„

ä¸ºäº†å‘è‡ªå®šä¹‰å‡½æ•°ä¼ é€’å¤æ‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ‚¨éœ€è¦åœ¨**æ•°æ®é¢„å¤„ç†é˜¶æ®µ**å°±å°†æ‰€æœ‰ç›¸å…³çš„é¢å¤–å­—æ®µèšåˆèµ·æ¥ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šå°†æ•°æ®é›†ä¸­é™¤ `prompt` å’Œ `label` ä¹‹å¤–çš„æ‰€æœ‰é™„åŠ ä¿¡æ¯ï¼ˆå¦‚ `session_id`, `user_profile`, `tool_code` ç­‰ï¼‰åˆå¹¶ï¼Œæ„é€ æˆä¸€ä¸ª**å•ä¸€çš„ã€ç»“æ„åŒ–çš„å­—æ®µ**ï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªåä¸º `metadata` çš„åˆ—ï¼Œå…¶å†…å®¹ä¸º JSON å­—ç¬¦ä¸²ï¼‰ã€‚

### æ­¥éª¤ä¸€ï¼šåœ¨æ•°æ®é›†ä¸­æ„é€  `metadata` å­—æ®µ

åœ¨è®­ç»ƒå¼€å§‹å‰ï¼Œæ‚¨éœ€è¦å¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œå¤„ç†ã€‚ä¾‹å¦‚ï¼Œæ‚¨çš„åŸå§‹æ•°æ®å¯èƒ½å¦‚ä¸‹ï¼š

| question | final_answer | session_id | tool_code |
| :--- | :--- | :--- | :--- |
| "..." | "..." | "sess_123" | "code_A" |

æ‚¨éœ€è¦å°†å…¶è½¬æ¢ä¸ºï¼š

| question | final_answer | metadata |
| :--- | :--- | :--- |
| "..." | "..." | `{"session_id": "sess_123", "tool_code": "code_A"}` |

### æ­¥éª¤äºŒï¼šåœ¨è®­ç»ƒè„šæœ¬ä¸­æŒ‡å®šæ˜ å°„

å®Œæˆæ•°æ®å‡†å¤‡åï¼Œåœ¨è®­ç»ƒè„šæœ¬ä¸­ï¼Œé€šè¿‡ `ROLLOUT_ARGS` å°†è¿™ä¸ªé¢„å¤„ç†å¥½çš„ `metadata` åˆ—æ˜ å°„åˆ° slime çš„ `Sample.metadata` å­—æ®µã€‚

```bash
ROLLOUT_ARGS=(
   # 1. æŒ‡å®šé¢„å¤„ç†åçš„æ•°æ®é›†æ–‡ä»¶
   --prompt-data /root/nq_search/train_processed.json

   # 2. å°† "question" åˆ—æ˜ å°„ä¸ºè¾“å…¥ prompt
   --input-key question

   # 3. å°† "final_answer" åˆ—æ˜ å°„ä¸ºè¯„ä¼°æ ‡ç­¾
   --label-key final_answer

   # 4. å°†é¢„å…ˆæ„é€ å¥½çš„ "metadata" åˆ—åŠ è½½åˆ° Sample.metadata
   #    slime ä¼šè‡ªåŠ¨å°†å…¶è§£æä¸º Python å­—å…¸
   --metadata-key metadata

   # ï¼ˆå¯é€‰ï¼‰å¦‚æœä½ çš„æ•°æ®é›†ä¸­åŒ…å« tool calling æ‰€éœ€çš„å·¥å…·å®šä¹‰ï¼Œå¯æä¾› tool åˆ—å¯¹åº”çš„ key
   # ä»¥ä¾¿ slime å°† tool schema åŠ è½½åˆ° `sample.metadata["tools"]`ï¼ˆç”¨äº message é©±åŠ¨çš„ tool-aware chat templateï¼‰
   # --tool-key tools
)
```

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ‚¨å°±å¯ä»¥åœ¨è‡ªå®šä¹‰çš„ `generate` æˆ– `reward` å‡½æ•°ä¸­ï¼Œé€šè¿‡ `sample.metadata['session_id']` ç­‰æ–¹å¼ï¼Œæ–¹ä¾¿åœ°è®¿é—®åˆ°æ‰€æœ‰é¢„å…ˆå‡†å¤‡å¥½çš„ç»“æ„åŒ–ä¿¡æ¯ã€‚

### ç¼–å†™è‡ªå®šä¹‰ç”Ÿæˆå‡½æ•°

é¦–å…ˆï¼Œé€šè¿‡ `--custom-generate-function-path` å‚æ•°æŒ‡å®šä¸€ä¸ªè‡ªå®šä¹‰çš„å¼‚æ­¥ Python å‡½æ•°ã€‚

**å‡½æ•°ç­¾å**: `async def generate(args, sample: Sample, sampling_params) -> Sample:`

**æ ¸å¿ƒå®ç°è¦ç‚¹**:

1.  **æ„å»ºäº¤äº’å¾ªç¯**: åˆ›å»ºå¾ªç¯ä»¥æ§åˆ¶æœ€å¤§äº¤äº’è½®æ¬¡ï¼ˆå¦‚ `for _ in range(max_turns):`ï¼‰ã€‚
2.  **è°ƒç”¨æ¨¡å‹ç”ŸæˆåŠ¨ä½œ**: æ¯è½®å¾ªç¯ä¸­ï¼Œè°ƒç”¨ SGLang æœåŠ¡ï¼Œè®©æ¨¡å‹æ ¹æ®å½“å‰å¯¹è¯å†å²ç”Ÿæˆä¸‹ä¸€æ­¥åŠ¨ä½œï¼ˆå¦‚ `<search>query</search>`ï¼‰ã€‚
3.  **è§£æå¹¶æ‰§è¡ŒåŠ¨ä½œ**: è§£ææ¨¡å‹è¾“å‡ºï¼Œè¯†åˆ«åŠ¨ä½œä¸å‚æ•°ï¼Œå¹¶è°ƒç”¨å¤–éƒ¨å·¥å…·æˆ– APIï¼ˆå¦‚ Google æœç´¢ï¼‰ã€‚
4.  **æ„å»ºè§‚å¯Ÿç»“æœ**: å°†å·¥å…·è¿”å›çš„ç»“æœæ ¼å¼åŒ–åï¼Œè¿½åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œä½œä¸ºä¸‹ä¸€è½®çš„è¾“å…¥ã€‚
5.  **å¤„ç† Loss Masking**: è¿™æ˜¯ Agent è®­ç»ƒçš„å…³é”®ã€‚
    -  éœ€è¦æ³¨æ„çš„æ˜¯ï¼š `loss_mask` åº”è¯¥å’Œ `response` ä¸€æ ·é•¿ï¼Œå…¶ä¸­éœ€è¦ç®— loss çš„ token ä¸º 1ï¼Œmask æ‰çš„ä¸º 0
    -   **æ¨¡å‹ç”Ÿæˆ**çš„ token (å¦‚æ€è€ƒã€åŠ¨ä½œæŒ‡ä»¤) â†’ `loss_mask` è®¾ä¸º `1`ï¼Œå‚ä¸æŸå¤±è®¡ç®—ã€‚
    -   **å·¥å…·æˆ–ç¯å¢ƒè¿”å›**çš„ token (å¦‚ API ç»“æœ) â†’ `loss_mask` è®¾ä¸º `0`ï¼Œä¸å‚ä¸æŸå¤±è®¡ç®—ã€‚
    -  å°æç¤ºï¼šå¦‚æœä½ çš„è‡ªå®šä¹‰ `generate()` æ˜¯ **message é©±åŠ¨** çš„ï¼ˆä½ æ‹¿åˆ° OpenAI `messages` + å¯é€‰çš„ `tools`ï¼‰ï¼Œå¯ä»¥ç”¨ `MultiTurnLossMaskGenerator` è‡ªåŠ¨ç”Ÿæˆå¯¹é½çš„ `token_ids` ä¸ tool-aware çš„ `loss_mask`ï¼š
       - `token_ids, full_loss_mask = MultiTurnLossMaskGenerator(tokenizer, tokenizer_type=args.loss_mask_type).get_loss_mask(messages, tools=tools)`
       - `response_length = get_response_lengths([full_loss_mask])[0]`ï¼Œå†è®¾ç½® `sample.tokens = token_ids`ã€`sample.response_length = response_length`ï¼Œä»¥åŠ `sample.loss_mask = full_loss_mask[-response_length:]`
       - å¦‚æœåœ¨ RL rollout ä¸­ä½ ç›´æ¥ä½¿ç”¨ **SGLang è¿”å›çš„ token ids**ï¼Œåˆ™ä¸è¦é‡æ–° tokenizeï¼›å»ºè®®æŒ‰è¿½åŠ  token æ®µçš„é•¿åº¦æ¥æ„é€  `loss_mask`ï¼Œä»¥ä¿è¯å¯¹é½ã€‚
6.  **ç»ˆæ­¢æ¡ä»¶**: å½“æ¨¡å‹ç”Ÿæˆç»ˆæ­¢æ ‡ç­¾ï¼ˆå¦‚ `<answer>...`ï¼‰æˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡æ—¶ï¼Œç»“æŸå¾ªç¯ã€‚
7.  **å°è£…è¿”å›**: å°†å®Œæ•´çš„äº¤äº’å†å²ã€token ID å’Œ `loss_masks` å¡«å……åˆ° `Sample` å¯¹è±¡ä¸­å¹¶è¿”å›ã€‚


**ä»£ç ç¤ºä¾‹ï¼ˆæ¦‚å¿µï¼‰**:
```python
async def generate(args, sample: Sample, sampling_params) -> Sample:
    # ... åˆå§‹åŒ– ...
    prompt, full_response, loss_masks = sample.prompt, "", []

    for _ in range(max_turns):
        # 1. æ¨¡å‹ç”ŸæˆåŠ¨ä½œ
        model_output = await call_sglang(prompt + full_response, ...)
        # ... tokenization and appending ...
        loss_masks += [1] * len(model_tokens) # loss_mask = 1
        full_response += model_output

        # 2. è§£æå¹¶æ‰§è¡ŒåŠ¨ä½œ
        action, content = parse_action(model_output)
        if action == "search":
            # 3 & 4. è·å–å¹¶è¿½åŠ è§‚å¯Ÿç»“æœ
            tool_output = await google_search(content)
            # ... tokenization and appending ...
            loss_masks += [0] * len(tool_tokens) # loss_mask = 0
            full_response += tool_output

        elif action == "answer":
            break # ç»“æŸå¾ªç¯

    # 7. å¡«å……å¹¶è¿”å› Sample å¯¹è±¡
    sample.response = full_response
    sample.tokens = ...
    sample.loss_mask = loss_masks
    return sample
```

### ç¼–å†™è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°

ç±»ä¼¼åœ°ï¼Œé€šè¿‡ `--custom-rm-path` æŒ‡å®šè‡ªå®šä¹‰å¥–åŠ±å‡½æ•°ã€‚

**å‡½æ•°ç­¾å**: `async def reward_func(args, sample: Sample, **kwargs) -> float:`

è¯¥å‡½æ•°æ¥æ”¶å®Œæ•´çš„ `Sample` å¯¹è±¡ï¼Œæ ¹æ®æœ€ç»ˆäº¤äº’ç»“æœè®¡ç®—å¾—åˆ†ã€‚å¯ä»¥åœ¨æ­¤å®ç°è‡ªå®šä¹‰è®¡åˆ†é€»è¾‘ï¼Œæˆ–è°ƒç”¨å¤–éƒ¨çš„ Reward Model æœåŠ¡ã€‚

### åœ¨è®­ç»ƒè„šæœ¬ä¸­é…ç½®

æœ€åï¼Œåœ¨è®­ç»ƒè„šæœ¬ä¸­ï¼Œé€šè¿‡ä»¥ä¸‹å‚æ•°å¯ç”¨ä¸Šè¿°è‡ªå®šä¹‰å‡½æ•°ï¼š

```bash
CUSTOM_ARGS=(
   # æŒ‡å®šè‡ªå®šä¹‰ç”Ÿæˆå‡½æ•°çš„è·¯å¾„ (æ ¼å¼: path.to.your.file:function_name)
   --custom-generate-function-path your_module.multiturn_logic:generate

   # æŒ‡å®šè‡ªå®šä¹‰å¥–åŠ±å‡½æ•°çš„è·¯å¾„
   --custom-rm-path your_module.multiturn_logic:reward_func
)
```

## å¤§è§„æ¨¡ MOE æ¨¡å‹çš„å¤šæœºè®­ç»ƒ

ä¸ºäº†å¯åŠ¨å¤šæœºä»»åŠ¡ï¼Œé¦–å…ˆéœ€è¦å¯åŠ¨ä¸€ä¸ª ray é›†ç¾¤ï¼Œå³åœ¨ node 0 è¿è¡Œï¼š

```bash
# Node0ï¼ˆHEADï¼‰
ray start --head --node-ip-address ${MASTER_ADDR} \
  --num-gpus 8 --disable-usage-stats

# å…¶ä»– Node
ray start --address=${MASTER_ADDR}:6379 --num-gpus 8
```

åœ¨ ray é›†ç¾¤å¯åŠ¨åï¼Œå¯ä»¥åœ¨ node 0 æäº¤ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼š

```bash
ray job submit --address="http://127.0.0.1:8265" \
   --runtime-env-json='{
     "env_vars": {
        "PYTHONPATH": "/root/Megatron-LM/",
        ... # e.g. no_proxyã€æ¥å£å˜é‡ç­‰
     }
   }' \
   -- python3 train.py \
   --...ï¼ˆå…¶ä»– Megatron/SGLang/slime å‚æ•°ï¼‰
```

slime é’ˆå¯¹å¤§è§„æ¨¡æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒè¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ã€‚æˆ‘ä»¬æä¾›äº†ä¸€äº›ç«¯åˆ°ç«¯çš„è®­ç»ƒæ¡ˆä¾‹ä»¥ä¾›å‚è€ƒï¼š

- [ç¤ºä¾‹ï¼š64xH100 è®­ç»ƒ GLM-4.5](../examples/glm4.5-355B-A32B.md)
- [ç¤ºä¾‹ï¼š128xH100 è®­ç»ƒ DeepSeek-R1](../examples/deepseek-r1.md)
