import logging
import concurrent.futures
import time
import os

from slime.utils.mask_utils import MultiTurnLossMaskGenerator
from slime.utils.processing_utils import load_processor, load_tokenizer

__all__ = ["generate_rollout"]

logger = logging.getLogger(__name__)

ROLLOUT_NUM_CPUS = os.environ.get("ROLLOUT_NUM_CPUS", 8)
TOKENIZER = None
PROCESSOR = None
MASK_GENERATOR = None
SAMPLE_PRINTED = False
_EXECUTOR = None


def _init_worker(hf_checkpoint, loss_mask_type):
    global TOKENIZER, PROCESSOR, MASK_GENERATOR
    TOKENIZER = load_tokenizer(hf_checkpoint, trust_remote_code=True)
    PROCESSOR = load_processor(hf_checkpoint, trust_remote_code=True)
    MASK_GENERATOR = MultiTurnLossMaskGenerator(TOKENIZER, tokenizer_type=loss_mask_type)


def _process_single_sample(messages, tools):
    token_ids, loss_mask = MASK_GENERATOR.get_loss_mask(messages, tools=tools)
    response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]
    return token_ids, loss_mask, response_length


def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    """An example to implement the generate_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_buffer: the data buffer to store the generated samples
        evaluation: bool, whether the rollout is for evaluation or not

    Returns:
        list[Sample]: a list of samples generated by the rollout
    """
    assert not evaluation
    assert args.rollout_global_dataset

    global TOKENIZER, PROCESSOR, MASK_GENERATOR, SAMPLE_PRINTED, _EXECUTOR
    
    samples = data_buffer.get_samples(args.rollout_batch_size)
    
    start_time = time.perf_counter()

    if _EXECUTOR is None:
        _EXECUTOR = concurrent.futures.ProcessPoolExecutor(
            max_workers=ROLLOUT_NUM_CPUS,
            initializer=_init_worker,
            initargs=(args.hf_checkpoint, args.loss_mask_type)
        )

    tasks = []
    for sample in samples:
        (s,) = sample
        tasks.append((s.prompt, s.metadata.get("tools", None)))

    results = list(_EXECUTOR.map(lambda x: _process_single_sample(*x), tasks))

    for i, (sample_wrapper, result) in enumerate(zip(samples, results)):
        (sample,) = sample_wrapper
        token_ids, loss_mask, response_length = result

        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]

        if i == 0 and not SAMPLE_PRINTED:
            logger.info(
                f"sft_rollout::generate_rollout example data: {sample=} (raw)prompt={sample.prompt} (raw){token_ids=} (raw){loss_mask=} {response_length=}"
            )
            SAMPLE_PRINTED = True

    total_time = time.perf_counter() - start_time
    logger.info(
        f"sft_rollout::generate_rollout rollout_id={rollout_id} batch_size={len(samples)} "
        f"total_time={total_time:.4f}s"
    )

    return samples
